[
  {
    "timestamp": "2024-11-27 19:33:39",
    "hash": "7eb2434b0e88b7cc9daad8d2ceed6f5a",
    "content": "创建实验\n​\n在开始之前\n​\n安装 SDK 并在您的代码中检查实验。\n导入用户操作数据作为度量实验影响的指标源。\n在哪里创建？\n​\n转到左侧边栏的\n实验\n部分，选择 \"\n实验\n\"，然后点击\n创建\n按钮。\n填写基本信息\n​\n● 实验 ID\n​\nID 只能包含字母、数字和下划线，例如，exp_image_optimization。\n● 所有者\n​\n实验创建者是默认所有者，可以根据需要添加额外的所有者，以便通过过滤进行实验管理。\n● 高级（可选）-- 添加层级\n​\n默认情况下，会自动为您当前的实验创建一个包含 100% 流量的专用层级，可以在 \"实验 -- 层级\" 下找到。通过勾选 \"添加层级\" 选项，您可以避免潜在的流量饥饿问题。您可以在此处选择在 \"实验 -- 层级\" 下创建的层级。您也可以直接在此页面上创建一个。有关层级的更多信息，请参阅\nABetterChoice.ai\n。\n设置实验目标\n​\n● 假设\n​\n描述您的实验计划的变化和理由。例如，基于数据分析，将 [xxx 功能] 从 [xxx] 改变为 [xxx] 预计会提高 xxx（效果）。[xxx 指标] 可以量化改进。\n● 选择指标\n​\n只允许一个主要指标，作为验证效益的核心指标。可以添加多个次要指标来评估与功能相关的效益。\n● 如何添加指标？\n​\n在左侧选中所需的指标，它们将出现在右侧。点击右侧的星形图标选择主要指标，它将显示在上方（红色框）。要取消选择一个指标，点击 \"x\" 按钮或使用图标（蓝色框）清除所有选择。\n分配和分组\n​\n● 流量分配\n​\n总流量百分比\n：确定用户参与实验的程度。如果在步骤 2 中选择了层级，分配的流量将不超过层级中定义的最大值。默认情况下，实验或层级的总流量设置为 100%。\n添加组\n：点击右侧的图标（蓝色框）添加组。在一个实验中最多可以添加一百个组，至少需要一个组。组名、流量比例和参数值都是可编辑的。所有实验组的流量百分比之和应为 100%。组的实际流量 = 总流量百分比 * 组的流量比例。\n添加参数\n：点击左侧的图标（蓝色框）添加参数。参数代表业务或功能策略。添加的数量无限制。\n值格式限制\n： 1.\n字符串\n：接受字符串、字母、数字和下划线。 2.\n数字\n：接受正/负整数、0、小数和科学记数法。 3.\n布尔值\n：FALSE 或 TRUE，控制组默认为 FALSE，治疗组默认为 TRUE。 4.\nJson\n：对象、数组、数字、字符串。它还允许嵌套结构，例如 {\"test\":{\"service\":{\"ctr_model\":0}}}。\n● 白名单（可选）\n​\n帮助确保您正在测试的每个变体都按预期工作。通过点击 \"添加组\"（蓝色框）从上一步中选择并添加组。\n● 目标受众（可选）\n​\n实验将仅针对指定受众中的用户。此外，您可以点击添加条件（蓝色框）添加多个条件，并在多个受众之间选择关系（AND/OR）。\n完成创建并开始\n​\n点击 \"创建\" 按钮后，您将收到成功创建通知，实验将显示在 \"实验 -- 实验\" 页面上。在生成的页面中，您可以通过点击右上角的图标开始实验并执行其他操作。\n",
    "has_update": true,
    "added_content": [],
    "removed_content": [],
    "summary": "内容已更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/features/create-experiment"
  },
  {
    "timestamp": "2024-11-27 19:34:25",
    "hash": "7eb2434b0e88b7cc9daad8d2ceed6f5a",
    "content": "创建实验\n​\n在开始之前\n​\n安装 SDK 并在您的代码中检查实验。\n导入用户操作数据作为度量实验影响的指标源。\n在哪里创建？\n​\n转到左侧边栏的\n实验\n部分，选择 \"\n实验\n\"，然后点击\n创建\n按钮。\n填写基本信息\n​\n● 实验 ID\n​\nID 只能包含字母、数字和下划线，例如，exp_image_optimization。\n● 所有者\n​\n实验创建者是默认所有者，可以根据需要添加额外的所有者，以便通过过滤进行实验管理。\n● 高级（可选）-- 添加层级\n​\n默认情况下，会自动为您当前的实验创建一个包含 100% 流量的专用层级，可以在 \"实验 -- 层级\" 下找到。通过勾选 \"添加层级\" 选项，您可以避免潜在的流量饥饿问题。您可以在此处选择在 \"实验 -- 层级\" 下创建的层级。您也可以直接在此页面上创建一个。有关层级的更多信息，请参阅\nABetterChoice.ai\n。\n设置实验目标\n​\n● 假设\n​\n描述您的实验计划的变化和理由。例如，基于数据分析，将 [xxx 功能] 从 [xxx] 改变为 [xxx] 预计会提高 xxx（效果）。[xxx 指标] 可以量化改进。\n● 选择指标\n​\n只允许一个主要指标，作为验证效益的核心指标。可以添加多个次要指标来评估与功能相关的效益。\n● 如何添加指标？\n​\n在左侧选中所需的指标，它们将出现在右侧。点击右侧的星形图标选择主要指标，它将显示在上方（红色框）。要取消选择一个指标，点击 \"x\" 按钮或使用图标（蓝色框）清除所有选择。\n分配和分组\n​\n● 流量分配\n​\n总流量百分比\n：确定用户参与实验的程度。如果在步骤 2 中选择了层级，分配的流量将不超过层级中定义的最大值。默认情况下，实验或层级的总流量设置为 100%。\n添加组\n：点击右侧的图标（蓝色框）添加组。在一个实验中最多可以添加一百个组，至少需要一个组。组名、流量比例和参数值都是可编辑的。所有实验组的流量百分比之和应为 100%。组的实际流量 = 总流量百分比 * 组的流量比例。\n添加参数\n：点击左侧的图标（蓝色框）添加参数。参数代表业务或功能策略。添加的数量无限制。\n值格式限制\n： 1.\n字符串\n：接受字符串、字母、数字和下划线。 2.\n数字\n：接受正/负整数、0、小数和科学记数法。 3.\n布尔值\n：FALSE 或 TRUE，控制组默认为 FALSE，治疗组默认为 TRUE。 4.\nJson\n：对象、数组、数字、字符串。它还允许嵌套结构，例如 {\"test\":{\"service\":{\"ctr_model\":0}}}。\n● 白名单（可选）\n​\n帮助确保您正在测试的每个变体都按预期工作。通过点击 \"添加组\"（蓝色框）从上一步中选择并添加组。\n● 目标受众（可选）\n​\n实验将仅针对指定受众中的用户。此外，您可以点击添加条件（蓝色框）添加多个条件，并在多个受众之间选择关系（AND/OR）。\n完成创建并开始\n​\n点击 \"创建\" 按钮后，您将收到成功创建通知，实验将显示在 \"实验 -- 实验\" 页面上。在生成的页面中，您可以通过点击右上角的图标开始实验并执行其他操作。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/features/create-experiment"
  },
  {
    "timestamp": "2024-11-27 19:34:55",
    "hash": "7eb2434b0e88b7cc9daad8d2ceed6f5a",
    "content": "创建实验\n​\n在开始之前\n​\n安装 SDK 并在您的代码中检查实验。\n导入用户操作数据作为度量实验影响的指标源。\n在哪里创建？\n​\n转到左侧边栏的\n实验\n部分，选择 \"\n实验\n\"，然后点击\n创建\n按钮。\n填写基本信息\n​\n● 实验 ID\n​\nID 只能包含字母、数字和下划线，例如，exp_image_optimization。\n● 所有者\n​\n实验创建者是默认所有者，可以根据需要添加额外的所有者，以便通过过滤进行实验管理。\n● 高级（可选）-- 添加层级\n​\n默认情况下，会自动为您当前的实验创建一个包含 100% 流量的专用层级，可以在 \"实验 -- 层级\" 下找到。通过勾选 \"添加层级\" 选项，您可以避免潜在的流量饥饿问题。您可以在此处选择在 \"实验 -- 层级\" 下创建的层级。您也可以直接在此页面上创建一个。有关层级的更多信息，请参阅\nABetterChoice.ai\n。\n设置实验目标\n​\n● 假设\n​\n描述您的实验计划的变化和理由。例如，基于数据分析，将 [xxx 功能] 从 [xxx] 改变为 [xxx] 预计会提高 xxx（效果）。[xxx 指标] 可以量化改进。\n● 选择指标\n​\n只允许一个主要指标，作为验证效益的核心指标。可以添加多个次要指标来评估与功能相关的效益。\n● 如何添加指标？\n​\n在左侧选中所需的指标，它们将出现在右侧。点击右侧的星形图标选择主要指标，它将显示在上方（红色框）。要取消选择一个指标，点击 \"x\" 按钮或使用图标（蓝色框）清除所有选择。\n分配和分组\n​\n● 流量分配\n​\n总流量百分比\n：确定用户参与实验的程度。如果在步骤 2 中选择了层级，分配的流量将不超过层级中定义的最大值。默认情况下，实验或层级的总流量设置为 100%。\n添加组\n：点击右侧的图标（蓝色框）添加组。在一个实验中最多可以添加一百个组，至少需要一个组。组名、流量比例和参数值都是可编辑的。所有实验组的流量百分比之和应为 100%。组的实际流量 = 总流量百分比 * 组的流量比例。\n添加参数\n：点击左侧的图标（蓝色框）添加参数。参数代表业务或功能策略。添加的数量无限制。\n值格式限制\n： 1.\n字符串\n：接受字符串、字母、数字和下划线。 2.\n数字\n：接受正/负整数、0、小数和科学记数法。 3.\n布尔值\n：FALSE 或 TRUE，控制组默认为 FALSE，治疗组默认为 TRUE。 4.\nJson\n：对象、数组、数字、字符串。它还允许嵌套结构，例如 {\"test\":{\"service\":{\"ctr_model\":0}}}。\n● 白名单（可选）\n​\n帮助确保您正在测试的每个变体都按预期工作。通过点击 \"添加组\"（蓝色框）从上一步中选择并添加组。\n● 目标受众（可选）\n​\n实验将仅针对指定受众中的用户。此外，您可以点击添加条件（蓝色框）添加多个条件，并在多个受众之间选择关系（AND/OR）。\n完成创建并开始\n​\n点击 \"创建\" 按钮后，您将收到成功创建通知，实验将显示在 \"实验 -- 实验\" 页面上。在生成的页面中，您可以通过点击右上角的图标开始实验并执行其他操作。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/features/create-experiment"
  },
  {
    "timestamp": "2024-11-27 19:37:21",
    "hash": "7eb2434b0e88b7cc9daad8d2ceed6f5a",
    "content": "创建实验\n​\n在开始之前\n​\n安装 SDK 并在您的代码中检查实验。\n导入用户操作数据作为度量实验影响的指标源。\n在哪里创建？\n​\n转到左侧边栏的\n实验\n部分，选择 \"\n实验\n\"，然后点击\n创建\n按钮。\n填写基本信息\n​\n● 实验 ID\n​\nID 只能包含字母、数字和下划线，例如，exp_image_optimization。\n● 所有者\n​\n实验创建者是默认所有者，可以根据需要添加额外的所有者，以便通过过滤进行实验管理。\n● 高级（可选）-- 添加层级\n​\n默认情况下，会自动为您当前的实验创建一个包含 100% 流量的专用层级，可以在 \"实验 -- 层级\" 下找到。通过勾选 \"添加层级\" 选项，您可以避免潜在的流量饥饿问题。您可以在此处选择在 \"实验 -- 层级\" 下创建的层级。您也可以直接在此页面上创建一个。有关层级的更多信息，请参阅\nABetterChoice.ai\n。\n设置实验目标\n​\n● 假设\n​\n描述您的实验计划的变化和理由。例如，基于数据分析，将 [xxx 功能] 从 [xxx] 改变为 [xxx] 预计会提高 xxx（效果）。[xxx 指标] 可以量化改进。\n● 选择指标\n​\n只允许一个主要指标，作为验证效益的核心指标。可以添加多个次要指标来评估与功能相关的效益。\n● 如何添加指标？\n​\n在左侧选中所需的指标，它们将出现在右侧。点击右侧的星形图标选择主要指标，它将显示在上方（红色框）。要取消选择一个指标，点击 \"x\" 按钮或使用图标（蓝色框）清除所有选择。\n分配和分组\n​\n● 流量分配\n​\n总流量百分比\n：确定用户参与实验的程度。如果在步骤 2 中选择了层级，分配的流量将不超过层级中定义的最大值。默认情况下，实验或层级的总流量设置为 100%。\n添加组\n：点击右侧的图标（蓝色框）添加组。在一个实验中最多可以添加一百个组，至少需要一个组。组名、流量比例和参数值都是可编辑的。所有实验组的流量百分比之和应为 100%。组的实际流量 = 总流量百分比 * 组的流量比例。\n添加参数\n：点击左侧的图标（蓝色框）添加参数。参数代表业务或功能策略。添加的数量无限制。\n值格式限制\n： 1.\n字符串\n：接受字符串、字母、数字和下划线。 2.\n数字\n：接受正/负整数、0、小数和科学记数法。 3.\n布尔值\n：FALSE 或 TRUE，控制组默认为 FALSE，治疗组默认为 TRUE。 4.\nJson\n：对象、数组、数字、字符串。它还允许嵌套结构，例如 {\"test\":{\"service\":{\"ctr_model\":0}}}。\n● 白名单（可选）\n​\n帮助确保您正在测试的每个变体都按预期工作。通过点击 \"添加组\"（蓝色框）从上一步中选择并添加组。\n● 目标受众（可选）\n​\n实验将仅针对指定受众中的用户。此外，您可以点击添加条件（蓝色框）添加多个条件，并在多个受众之间选择关系（AND/OR）。\n完成创建并开始\n​\n点击 \"创建\" 按钮后，您将收到成功创建通知，实验将显示在 \"实验 -- 实验\" 页面上。在生成的页面中，您可以通过点击右上角的图标开始实验并执行其他操作。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/features/create-experiment"
  },
  {
    "timestamp": "2024-11-27 19:40:22",
    "hash": "e934a4bb858f4dfb45bf6b0503b00d8e",
    "content": "关于 ABetterChoice\n​\nABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、\n实验分析\n和\nROI 仪表盘\n，以便于进行在线实验。\n入门指南\n​\n要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：\n创建项目\n：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。\nSDK 集成\n：集成 SDK 以快速开始收集洞察。\n数据连接\n：本指南介绍如何将您的数据源连接到 ABetterChoice。\n数据源与指标\n：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。\n开始您的第一个实验\n：本指南介绍如何在 ABetterChoice 中创建并运行实验。\n实验分析\n：本指南介绍如何解读 ABetterChoice 中的实验结果。\n如何使用 ROI 仪表盘\n：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。\n",
    "has_update": true,
    "added_content": [
      "关于 ABetterChoice",
      "​",
      "ABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、",
      "实验分析",
      "和",
      "ROI 仪表盘",
      "，以便于进行在线实验。",
      "入门指南",
      "​",
      "要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：",
      "创建项目",
      "：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。",
      "SDK 集成",
      "：集成 SDK 以快速开始收集洞察。",
      "数据连接",
      "：本指南介绍如何将您的数据源连接到 ABetterChoice。",
      "数据源与指标",
      "：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。",
      "开始您的第一个实验",
      "：本指南介绍如何在 ABetterChoice 中创建并运行实验。",
      "实验分析",
      "：本指南介绍如何解读 ABetterChoice 中的实验结果。",
      "如何使用 ROI 仪表盘",
      "：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。"
    ],
    "removed_content": [],
    "summary": "新增内容: 关于 ABetterChoice...",
    "url": "https://docs.abetterchoice.ai/zh/guide/getting-started/overview",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:40:24",
    "hash": "e1b5ce3557f17232fbfe758ac92eee8e",
    "content": "Platform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPlatform\nResources\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\nPlatform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\n📢 Announcing the Statsig <> Azure AI Integration\n·\nLearn more\nfunction scrollCalendarContainer(pixels) {\n    $d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })\n  }\nProduct Updates\nNov 2024\n⏱️Experiment Compute Overview\n🏭 Autoscale on Snowflake WHN\n👁️ Single value views\n➕Cumulative Sum Rollups\n📐Retention Metrics on Statsig WHN\nOct 2024\n🎉 SCIM User Provisioning\n📋 Dynamic Configs Now Have Templates!\n⏱️WHN Compute Transparency\n⚡Inline Power Analysis\n🥇 First-Value metrics\n🔍 Focused Analysis with Top Group Limits\n🪵🪄 Log transforms\n⌚💰📊 Latest value metrics\n🧲 Group-by in Retention Analysis\n👯 Cohort analysis in all charts types\n📊 Cohort Analysis in Funnels\n🪜Funnels Now Support Up to 15 Steps\n🔗 Improved Segment Integration\n⏱️ 2x Funnel Performance Improvements\n💥 Cross-Environment Feature Gates View\n🚫 Metrics Update: Deprecating event_dau metric\nSep 2024\n🕧 Time to Complete Metrics\n⏳Funnels ++ on WHN\n📊 Distribution Analysis of Event Property Values\n% Percentage-Based Grouping\n⏰ Time Period Comparison in Funnels\n⏳ Funnels - Time to Convert Improvements\n⏸️ Pause Experiment Assignment\n🔔 Email Notification Preferences\n👤 ID Resolution++\nAug 2024\n🎛️ Dashboard Filters\n🧠 Experiment Knowledge Base\n🎓 Meta Analysis : August Release\n🧲 Retention Overhaul\n✨🛤️✨User Journeys Overhaul\n📅 Expanded Chart Granularities and MAU support\n📧 Dashboard PDF Export\n🚀❤️📊 Statsig <3 Funnels\n🕒 Session Analytics Private Beta\n📋 Custom Experiment Checklist\n📈 WHN Product Analytics\n🤖 Bot Filtering\n🤳 Parameter Stores\nJul 2024\n📊 Benjamini-Hochberg\n🔗 Combine Events in Funnel Steps\n🔍 First-Time Filters in Funnels\n🌊 Session Streams\n⌨️ Keyboard Navigation\n📊 Outlier Detection\n💾 Reusable Cohorts\n🧢 Capped Metrics (WHN)\n🕵 Differential Impact Detection\n💄 New look and feel on Statsig\n👩‍💻 Statsig Managed API Proxy\n🏠 New Home Experience\n🧮 Improved Formula Support\n🙋‍♀️ User Management v2\n🎓 Meta Analysis : July release\nJun 2024\n🌓 One Sided Tests\n♻️ WHN Statsig Table Lifecycle\n✨Dashboard Templates\n🧭 Updated navigation\n👩🏼‍💻 Statsig CLI (”Siggy”)\n📍 Advanced Local Metrics - WHN\n🔽 Pulse Lift View Selector\nℹ️ Metric Detail Cards\n💻 New Suite of Javascript SDKs\n🎓 Meta-analysis : June Release\nMay 2024\n⚡WHN SDK events now hourly\n💾 Saved Queries\n💻 Web Analytics\n🎯 Inline Targeting Criteria\n🎂 Stratified Sampling\n📃 Tables as Metric Sources\n🥷🏼 Statsig ID Resolver\n🎯 Multi-Event Cohorts\n🫀 SDK Health Visibility\n🔽 Funnels 2.0\nApr 2024\n🎯 Assignment Filtering on WHN\n📏 Threshold Metrics on WHN\n🧢 Capped Metrics\n⏯️ Statsig Session Replay Beta\n👥 Teams Configuration Settings\n🆕 Refreshing Pulse (Scorecards)\n📍Local Metrics on WHN\n📋 Schemas for Dynamic Configs\n💬 Comments in Dynamic Configs\n🧮 More Metric Flexibility on WHN\nMar 2024\n🌸 Dashboards Spring Cleaning\n📤 Templates\n🍯 Persistent Assignment\n🚨 Alerts++\n% Percentile Metrics\n🥽 visionOS support\n🔍 Diagnostics 2.0\n🧮 New Metric Types on WHN\n🤼 Teams\nFeb 2024\nSlice by Feature Gate group in Metrics Explorer\n🚫 Read Only Metric Definitions\nSlice Experiments by User Dimension in Metrics Explorer\nUser Journeys (Beta)\n👤 Anonymous -> User ID\n🕒 Scheduled Reloads\n🤖 Statbot (in Console)\n✅ Verified Metrics\nJan 2024\nEvent-Based Cohorts in Metrics Explorer\nSlice by Experiment Group in Metrics Explorer\nNew Group Assignment Health Check\nDec 2023\nNew Year, New (& Improved) Console\nNew & Improved Custom Queries\nNov 2023\nEnhanced Formulas in Metrics Explorer\n📣 Interactive Experiment Summaries\nImproved Power Analysis Calculator\nOct 2023\n📊 Improving Charts in Dashboards\nExperiment Summary PDF\nSep 2023\nNew Experiment Scorecard (Pulse) Views\n🪦Metric Archival\nAug 2023\n📝 Smart Scorecard Limits\n🚨Experiment Policy\n👩‍💻 Github Code References\nNew & Improved Experiment Setup Checklist\nBetter Experiment Defaults\nJul 2023\nAnalytics : Custom retention reports\nExperiment on the edge with Fastly\nBayesian Analysis for Experiments\n📊Bar Charts in Metrics Explorer\nStatsig Warehouse Native\nJun 2023\nCustom roles for Role Based Access Control\n📈 Metrics Explorer\nFaster Users Tab to troubleshoot in production\nMay 2023\nTargeting on Holdouts\n⌛ 90-day Pulse expiration\nCloning Metrics\nApr 2023\nFaster Pulse, Environments in Overrides, Experiment Duration by Exposures\nManual assignment for Stratified Sampling\nWarehouse ingestion tab makeover\nMar 2023\n📊 Explore metrics outside just an experiment\n🧮 Including targeting gates in your power calculations\nLeft navigation bar auto-collapse, permanent and stale gates\nMetric Alerts\nComposite Sums, Pass Rate Filter, Permanent Gates, and More\nFeb 2023\nFlexible Environment Configuration and Metrics Directionality\nDatadog Trigger Integration\nManaging Feature Gate Lifecycle, Including Cleanup\nJan 2023\nMetrics Archival, Deletion and More!\nDec 2022\nHistorical Pulse Results, Following Tags, and Custom Metrics Improvements\nData Warehouse Ingestion\nMonitoring Metrics & Explore in Feature Gates\nNov 2022\nNew Slack Integration\nOct 2022\nv1 Dashboards, Discussion Tags, and Advanced Search\nDeeper Amplitude Integration\nNew Sequential Testing Capabilities\nSep 2022\nExperiment Setup Configuration UX, Automated A/A Test Reports, and more\nBroader ID Support in Autotune and Downloadable Events Explorer Results\nHome Tab Updates\nSnowflake, Redshift, BigQuery Data Warehouse Support\nAug 2022\nExplore Tab, Search Improvements, and More\nReviews at Various Levels, Metrics Bulk Management, New Users Tab, and More\nJul 2022\nImages for Experiment Groups\nMetrics Logstream and Experiment Checklist\nExperiment Scorecard and CUPED\nJun 2022\nCustom Metrics, Filtered Search, and more\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nExperiment Compute Summary\nFollowing up from the Statsig\nproject level compute summary\n, we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to\noptimize costs\n.\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nAutoscaling on Snowflake (Warehouse Native)\nYou can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to\nSettings > Project > Data Connection,\nand select\nSet up additional Warehouses\n.\nWhen you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.\nWe have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!\n11/20/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n👁️ Updated\nSingle Value Views in Metric Drilldown and Dashboards\nUse Case\nWhen you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.\nWhy It’s Important\nSingle Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.\nThe Feature: What It Does\nYou can now directly select\nSingle Value\nas a widget type when adding items to your\nDashboards\n, making it easier to showcase key metrics prominently without additional configuration.\nIn addition, within\nMetric Drilldown\n, you can choose the Single Value view to display your metric as a headline figure. This feature offers:\nLatest Full Data Point:\nView the most recent complete data point (e.g., yesterday’s total sales or user activities).\nOverall Value for Time Range:\nSee the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.\nComparison Options:\nSelect a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.\nBy incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.\n11/5/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n➕Cumulative Sum Rollups in Metric Drilldown\nUse Case\nWhen analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:\n“How many times has this feature ever been used?\n“How many distinct people have ever used this feature?”\n“What is the total revenue generated up to this point?”\nWhy It’s Important\nViewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.\nThe Feature: What It Does\nIn\nMetric Drilldown\n, after selecting an event and choosing an aggregation method—such as\nEvent Count\n,\nUniques\n,\nAverage of Property Value\n, etc.—you can now apply the\nCumulative Sum\noption to your results. This feature accumulates your selected metric over time, providing a running total in your charts.\nWhen the metric aggregation is set to\nUniques\n, you have two options for calculating the cumulative sum:\nDistinct Uniques\nWhat it does\n: Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.\nUse Case\n: Answers\n“How many distinct people have ever used this feature?”\nby providing a deduplicated cumulative count.\nTotal Uniques\nWhat it does\n: Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.\nUse Case\n: Helps you understand\n“What is the total number of unique user engagements over time, including repeat users?”\nThis provides insight into recurring user activity across different periods.\nFor other aggregation types:\nEvent Count\n: The cumulative sum shows the total number of events over time, helping you track overall engagement.\nAverage of Property Value\n: Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.\nSum of Property Value:\nAccumulates the sum of a chosen property value from your events, useful for questions like \"\nWhat is the total revenue generated up to this point?\"\nor\n“What is the cumulative sum of this property over time?”\nby providing the total accumulated value.\nBy enabling the\nCumulative Sum\noption, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.\n11/4/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\nStatsig Cloud launched with user accounting metrics -\nincluding retention\n. We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!\nRetention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.\nThis allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.\nThis class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo\nused retention metrics\nto measure and drive long-term install and revenue growth.\nCheck out the\ndocs\n, and try it out in Warehouse Native today!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nIntroducing Open-Beta SCIM Support on Statsig\nWe're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,\nStatsig Docs\n.\nThis is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!\nKey Features\nUser Provisioning\n: Automatically create and manage user accounts in Statsig based on Okta identities\nRole Assignment\n: Easily assign and manage user roles through Okta, ensuring consistent access controls\nBenefits:\nStreamlined User Management\n: Simplify the onboarding process with automated account creation and updates.\nEnhanced Security\n: Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.\nImproved Efficiency\n: Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.\nScalability\n: Easily manage user identities as your organization grows, without the hassle of manual interventions.\nThis enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nExtending Templates to Dynamic Configs\nOver the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!\nQuick context on Dynamic Configs\nDynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.\nTemplates\nTemplates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via\nOrganization Settings\nand\nRole-based Access Controls\n) or at the\nTeam-level\n.\n10/29/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nWarehouse Native Compute Transparency Dashboard\nStatsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.\nCommon customers we've designed the dashboard to be able to address include\nWhat Metric Sources take the most compute time (useful to focus optimization effort here; see tips\nhere\n)\nWhat is the split of compute time between full loads vs incremental loads vs custom queries?\nHow is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)\nYou can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview\nThis is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.\n10/25/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nPower Analysis attached to Experiments\nPower Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.\nThis feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.\nExperiment Setup Screen\nStarting Power Analysis from an Experiment\n10/25/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\n🥇 First-Value metrics\nAlongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.\nLearn more in\nour documentation\nJoin the #1 experimentation community\nConnect with like-minded product leaders, data scientists, \n      and engineers to share the latest in product experimentation.\nJoin Community\nOlder updates\nTry Statsig Today\nGet started for free. Add your whole team!\nSign up for Free\nTest Drive Now\nWhy the best build with us\nTestimonials\nAt OpenAI, we want to iterate as fast as possible.\nStatsig enables us to grow, scale, and learn efficiently\n. Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.\nOpenAI\nDave Cummings\nEngineering Manager, ChatGPT\nMore stories\nBrex's mission is to help businesses move fast.\nStatsig is now helping our engineers move fast\n. It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.\nBrex\nKarandeep Anand\nPresident\nMore stories\nAt Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.\nStatsig's experimentation platform enables both this speed and learning for us\n.\nNotion\nMengying Li\nData Science Manager\nMore stories\nWe evaluated Optimizely, LaunchDarkly, Split, and Eppo, but\nultimately selected Statsig due to its comprehensive end-to-end integration\n. We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.\nSoundCloud\nDon Browning\nSVP, Data & Platform Engineering\nMore stories\nWe only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.\nWe are definitely heading in the right direction with Statsig\n.\nAncestry\nPartha Sarathi\nDirector of Engineering\nMore stories\nconst vocLength = 5;\n  let prevSelectedVoiceIndex = vocLength - 1;\n  function _selectVoice(index) {\n    if (index === prevSelectedVoiceIndex) {\n      return;\n    }\n    const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;\n    const voiceId = `voiceHeading${index}`;\n    $d(prevVoiceId).classList.remove('selected');\n    $d(voiceId).classList.add('selected');\n\n    const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;\n    const voiceContentId = `voiceContent${index}`;\n    $d(prevVoiceContentId).style.opacity = 0;\n    $d(prevVoiceContentId).classList.remove('onTop');\n    $d(voiceContentId).style.opacity = 1;\n    $d(voiceContentId).classList.add('onTop');\n\n    prevSelectedVoiceIndex = index;\n  }\n  _selectVoice(0);\nWe use cookies to ensure you get the best experience on our website.\nPrivacy Policy\nGot it!\nid=\"cookieConsent\"\nid=\"pageContent\"\nid=\"pageBody\"\nconst ccKey = '_cc_shown=1';\n  window.__ccKey = ccKey;\n  function setCookieConsent() {\n    let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);\n    document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;\n    document.getElementById('cookieConsent').style.display = 'none';\n  }\nBuild. Measure. Ship. Confidently!\nGet Started\nBook a Live Demo\nPlatform\nFeature Management\nExperimentation\nData Warehouse\nProduct Analytics\nSession Replay\nWeb Analytics\nAll Features\nTest Drive Now\nWhy Statsig\nProduct Observability\nHow It Works\nBuild vs Buy\nPricing\nCustomer Stories\nTestimonials\nResources\nDocs\nCode\nBlog\nProduct Updates\n<li>\n                <a href=\"/kb\" data-event-value=\"kb\">\n                  Knowledge Base\n                </a>\n              </li>\nA/B Test Calculator\nIntegrations\nStartup Program\nJoin Community\nEvents\nFeedback\nStatus\nCompany\nAbout Us\nCareers\nPets\nTerms\nPrivacy Policy\nContact Us\n© 2024 Statsig, Inc.\nHello from Bellevue, WA\n",
    "has_update": true,
    "added_content": [
      "Platform",
      "Resources",
      "Docs",
      "Blog",
      "Pricing",
      "Sign In",
      "Book a Live Demo",
      "Platform",
      "Resources",
      "PRODUCTS",
      "Experimentation",
      "Feature Flags",
      "Warehouse Native",
      "Product Analytics",
      "Session Replay",
      "Web Analytics",
      "ROLES",
      "Engineering",
      "Dev Ops",
      "Data Science",
      "Product Management",
      "INDUSTRIES",
      "Artificial Intelligence",
      "Gaming",
      "B2B Saas",
      "E-Commerce",
      "Customer Stories",
      "Startups",
      "Integrations",
      "A/B Testing Calculator",
      "Support",
      "Product Updates",
      "Platform",
      "Resources",
      "Docs",
      "Blog",
      "Pricing",
      "Sign In",
      "Book a Live Demo",
      "PRODUCTS",
      "Experimentation",
      "Feature Flags",
      "Warehouse Native",
      "Product Analytics",
      "Session Replay",
      "Web Analytics",
      "ROLES",
      "Engineering",
      "Dev Ops",
      "Data Science",
      "Product Management",
      "INDUSTRIES",
      "Artificial Intelligence",
      "Gaming",
      "B2B Saas",
      "E-Commerce",
      "Customer Stories",
      "Startups",
      "Integrations",
      "A/B Testing Calculator",
      "Support",
      "Product Updates",
      "📢 Announcing the Statsig <> Azure AI Integration",
      "·",
      "Learn more",
      "function scrollCalendarContainer(pixels) {",
      "$d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })",
      "}",
      "Product Updates",
      "Nov 2024",
      "⏱️Experiment Compute Overview",
      "🏭 Autoscale on Snowflake WHN",
      "👁️ Single value views",
      "➕Cumulative Sum Rollups",
      "📐Retention Metrics on Statsig WHN",
      "Oct 2024",
      "🎉 SCIM User Provisioning",
      "📋 Dynamic Configs Now Have Templates!",
      "⏱️WHN Compute Transparency",
      "⚡Inline Power Analysis",
      "🥇 First-Value metrics",
      "🔍 Focused Analysis with Top Group Limits",
      "🪵🪄 Log transforms",
      "⌚💰📊 Latest value metrics",
      "🧲 Group-by in Retention Analysis",
      "👯 Cohort analysis in all charts types",
      "📊 Cohort Analysis in Funnels",
      "🪜Funnels Now Support Up to 15 Steps",
      "🔗 Improved Segment Integration",
      "⏱️ 2x Funnel Performance Improvements",
      "💥 Cross-Environment Feature Gates View",
      "🚫 Metrics Update: Deprecating event_dau metric",
      "Sep 2024",
      "🕧 Time to Complete Metrics",
      "⏳Funnels ++ on WHN",
      "📊 Distribution Analysis of Event Property Values",
      "% Percentage-Based Grouping",
      "⏰ Time Period Comparison in Funnels",
      "⏳ Funnels - Time to Convert Improvements",
      "⏸️ Pause Experiment Assignment",
      "🔔 Email Notification Preferences",
      "👤 ID Resolution++",
      "Aug 2024",
      "🎛️ Dashboard Filters",
      "🧠 Experiment Knowledge Base",
      "🎓 Meta Analysis : August Release",
      "🧲 Retention Overhaul",
      "✨🛤️✨User Journeys Overhaul",
      "📅 Expanded Chart Granularities and MAU support",
      "📧 Dashboard PDF Export",
      "🚀❤️📊 Statsig <3 Funnels",
      "🕒 Session Analytics Private Beta",
      "📋 Custom Experiment Checklist",
      "📈 WHN Product Analytics",
      "🤖 Bot Filtering",
      "🤳 Parameter Stores",
      "Jul 2024",
      "📊 Benjamini-Hochberg",
      "🔗 Combine Events in Funnel Steps",
      "🔍 First-Time Filters in Funnels",
      "🌊 Session Streams",
      "⌨️ Keyboard Navigation",
      "📊 Outlier Detection",
      "💾 Reusable Cohorts",
      "🧢 Capped Metrics (WHN)",
      "🕵 Differential Impact Detection",
      "💄 New look and feel on Statsig",
      "👩‍💻 Statsig Managed API Proxy",
      "🏠 New Home Experience",
      "🧮 Improved Formula Support",
      "🙋‍♀️ User Management v2",
      "🎓 Meta Analysis : July release",
      "Jun 2024",
      "🌓 One Sided Tests",
      "♻️ WHN Statsig Table Lifecycle",
      "✨Dashboard Templates",
      "🧭 Updated navigation",
      "👩🏼‍💻 Statsig CLI (”Siggy”)",
      "📍 Advanced Local Metrics - WHN",
      "🔽 Pulse Lift View Selector",
      "ℹ️ Metric Detail Cards",
      "💻 New Suite of Javascript SDKs",
      "🎓 Meta-analysis : June Release",
      "May 2024",
      "⚡WHN SDK events now hourly",
      "💾 Saved Queries",
      "💻 Web Analytics",
      "🎯 Inline Targeting Criteria",
      "🎂 Stratified Sampling",
      "📃 Tables as Metric Sources",
      "🥷🏼 Statsig ID Resolver",
      "🎯 Multi-Event Cohorts",
      "🫀 SDK Health Visibility",
      "🔽 Funnels 2.0",
      "Apr 2024",
      "🎯 Assignment Filtering on WHN",
      "📏 Threshold Metrics on WHN",
      "🧢 Capped Metrics",
      "⏯️ Statsig Session Replay Beta",
      "👥 Teams Configuration Settings",
      "🆕 Refreshing Pulse (Scorecards)",
      "📍Local Metrics on WHN",
      "📋 Schemas for Dynamic Configs",
      "💬 Comments in Dynamic Configs",
      "🧮 More Metric Flexibility on WHN",
      "Mar 2024",
      "🌸 Dashboards Spring Cleaning",
      "📤 Templates",
      "🍯 Persistent Assignment",
      "🚨 Alerts++",
      "% Percentile Metrics",
      "🥽 visionOS support",
      "🔍 Diagnostics 2.0",
      "🧮 New Metric Types on WHN",
      "🤼 Teams",
      "Feb 2024",
      "Slice by Feature Gate group in Metrics Explorer",
      "🚫 Read Only Metric Definitions",
      "Slice Experiments by User Dimension in Metrics Explorer",
      "User Journeys (Beta)",
      "👤 Anonymous -> User ID",
      "🕒 Scheduled Reloads",
      "🤖 Statbot (in Console)",
      "✅ Verified Metrics",
      "Jan 2024",
      "Event-Based Cohorts in Metrics Explorer",
      "Slice by Experiment Group in Metrics Explorer",
      "New Group Assignment Health Check",
      "Dec 2023",
      "New Year, New (& Improved) Console",
      "New & Improved Custom Queries",
      "Nov 2023",
      "Enhanced Formulas in Metrics Explorer",
      "📣 Interactive Experiment Summaries",
      "Improved Power Analysis Calculator",
      "Oct 2023",
      "📊 Improving Charts in Dashboards",
      "Experiment Summary PDF",
      "Sep 2023",
      "New Experiment Scorecard (Pulse) Views",
      "🪦Metric Archival",
      "Aug 2023",
      "📝 Smart Scorecard Limits",
      "🚨Experiment Policy",
      "👩‍💻 Github Code References",
      "New & Improved Experiment Setup Checklist",
      "Better Experiment Defaults",
      "Jul 2023",
      "Analytics : Custom retention reports",
      "Experiment on the edge with Fastly",
      "Bayesian Analysis for Experiments",
      "📊Bar Charts in Metrics Explorer",
      "Statsig Warehouse Native",
      "Jun 2023",
      "Custom roles for Role Based Access Control",
      "📈 Metrics Explorer",
      "Faster Users Tab to troubleshoot in production",
      "May 2023",
      "Targeting on Holdouts",
      "⌛ 90-day Pulse expiration",
      "Cloning Metrics",
      "Apr 2023",
      "Faster Pulse, Environments in Overrides, Experiment Duration by Exposures",
      "Manual assignment for Stratified Sampling",
      "Warehouse ingestion tab makeover",
      "Mar 2023",
      "📊 Explore metrics outside just an experiment",
      "🧮 Including targeting gates in your power calculations",
      "Left navigation bar auto-collapse, permanent and stale gates",
      "Metric Alerts",
      "Composite Sums, Pass Rate Filter, Permanent Gates, and More",
      "Feb 2023",
      "Flexible Environment Configuration and Metrics Directionality",
      "Datadog Trigger Integration",
      "Managing Feature Gate Lifecycle, Including Cleanup",
      "Jan 2023",
      "Metrics Archival, Deletion and More!",
      "Dec 2022",
      "Historical Pulse Results, Following Tags, and Custom Metrics Improvements",
      "Data Warehouse Ingestion",
      "Monitoring Metrics & Explore in Feature Gates",
      "Nov 2022",
      "New Slack Integration",
      "Oct 2022",
      "v1 Dashboards, Discussion Tags, and Advanced Search",
      "Deeper Amplitude Integration",
      "New Sequential Testing Capabilities",
      "Sep 2022",
      "Experiment Setup Configuration UX, Automated A/A Test Reports, and more",
      "Broader ID Support in Autotune and Downloadable Events Explorer Results",
      "Home Tab Updates",
      "Snowflake, Redshift, BigQuery Data Warehouse Support",
      "Aug 2022",
      "Explore Tab, Search Improvements, and More",
      "Reviews at Various Levels, Metrics Bulk Management, New Users Tab, and More",
      "Jul 2022",
      "Images for Experiment Groups",
      "Metrics Logstream and Experiment Checklist",
      "Experiment Scorecard and CUPED",
      "Jun 2022",
      "Custom Metrics, Filtered Search, and more",
      "11/26/2024",
      "Permalink ›",
      "Vineeth Madhusudanan",
      "Product Manager, Statsig",
      "Experiment Compute Summary",
      "Following up from the Statsig",
      "project level compute summary",
      ", we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to",
      "optimize costs",
      ".",
      "11/26/2024",
      "Permalink ›",
      "Vineeth Madhusudanan",
      "Product Manager, Statsig",
      "Autoscaling on Snowflake (Warehouse Native)",
      "You can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to",
      "Settings > Project > Data Connection,",
      "and select",
      "Set up additional Warehouses",
      ".",
      "When you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.",
      "We have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!",
      "11/20/2024",
      "Permalink ›",
      "Akin Olugbade",
      "Product Manager, Statsig",
      "👁️ Updated",
      "Single Value Views in Metric Drilldown and Dashboards",
      "Use Case",
      "When you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.",
      "Why It’s Important",
      "Single Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.",
      "The Feature: What It Does",
      "You can now directly select",
      "Single Value",
      "as a widget type when adding items to your",
      "Dashboards",
      ", making it easier to showcase key metrics prominently without additional configuration.",
      "In addition, within",
      "Metric Drilldown",
      ", you can choose the Single Value view to display your metric as a headline figure. This feature offers:",
      "Latest Full Data Point:",
      "View the most recent complete data point (e.g., yesterday’s total sales or user activities).",
      "Overall Value for Time Range:",
      "See the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.",
      "Comparison Options:",
      "Select a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.",
      "By incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.",
      "11/5/2024",
      "Permalink ›",
      "Akin Olugbade",
      "Product Manager, Statsig",
      "➕Cumulative Sum Rollups in Metric Drilldown",
      "Use Case",
      "When analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:",
      "“How many times has this feature ever been used?",
      "“How many distinct people have ever used this feature?”",
      "“What is the total revenue generated up to this point?”",
      "Why It’s Important",
      "Viewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.",
      "The Feature: What It Does",
      "In",
      "Metric Drilldown",
      ", after selecting an event and choosing an aggregation method—such as",
      "Event Count",
      ",",
      "Uniques",
      ",",
      "Average of Property Value",
      ", etc.—you can now apply the",
      "Cumulative Sum",
      "option to your results. This feature accumulates your selected metric over time, providing a running total in your charts.",
      "When the metric aggregation is set to",
      "Uniques",
      ", you have two options for calculating the cumulative sum:",
      "Distinct Uniques",
      "What it does",
      ": Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.",
      "Use Case",
      ": Answers",
      "“How many distinct people have ever used this feature?”",
      "by providing a deduplicated cumulative count.",
      "Total Uniques",
      "What it does",
      ": Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.",
      "Use Case",
      ": Helps you understand",
      "“What is the total number of unique user engagements over time, including repeat users?”",
      "This provides insight into recurring user activity across different periods.",
      "For other aggregation types:",
      "Event Count",
      ": The cumulative sum shows the total number of events over time, helping you track overall engagement.",
      "Average of Property Value",
      ": Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.",
      "Sum of Property Value:",
      "Accumulates the sum of a chosen property value from your events, useful for questions like \"",
      "What is the total revenue generated up to this point?\"",
      "or",
      "“What is the cumulative sum of this property over time?”",
      "by providing the total accumulated value.",
      "By enabling the",
      "Cumulative Sum",
      "option, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.",
      "11/4/2024",
      "Permalink ›",
      "Craig Sexauer",
      "Data Scientist, Statsig",
      "Statsig Cloud launched with user accounting metrics -",
      "including retention",
      ". We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!",
      "Retention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.",
      "This allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.",
      "This class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo",
      "used retention metrics",
      "to measure and drive long-term install and revenue growth.",
      "Check out the",
      "docs",
      ", and try it out in Warehouse Native today!",
      "10/31/2024",
      "Permalink ›",
      "Shubham Singhal",
      "Product Manager, Statsig",
      "Introducing Open-Beta SCIM Support on Statsig",
      "We're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,",
      "Statsig Docs",
      ".",
      "This is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!",
      "Key Features",
      "User Provisioning",
      ": Automatically create and manage user accounts in Statsig based on Okta identities",
      "Role Assignment",
      ": Easily assign and manage user roles through Okta, ensuring consistent access controls",
      "Benefits:",
      "Streamlined User Management",
      ": Simplify the onboarding process with automated account creation and updates.",
      "Enhanced Security",
      ": Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.",
      "Improved Efficiency",
      ": Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.",
      "Scalability",
      ": Easily manage user identities as your organization grows, without the hassle of manual interventions.",
      "This enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!",
      "10/31/2024",
      "Permalink ›",
      "Shubham Singhal",
      "Product Manager, Statsig",
      "Extending Templates to Dynamic Configs",
      "Over the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!",
      "Quick context on Dynamic Configs",
      "Dynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.",
      "Templates",
      "Templates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via",
      "Organization Settings",
      "and",
      "Role-based Access Controls",
      ") or at the",
      "Team-level",
      ".",
      "10/29/2024",
      "Permalink ›",
      "Vineeth Madhusudanan",
      "Product Manager, Statsig",
      "Warehouse Native Compute Transparency Dashboard",
      "Statsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.",
      "Common customers we've designed the dashboard to be able to address include",
      "What Metric Sources take the most compute time (useful to focus optimization effort here; see tips",
      "here",
      ")",
      "What is the split of compute time between full loads vs incremental loads vs custom queries?",
      "How is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)",
      "You can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview",
      "This is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.",
      "10/25/2024",
      "Permalink ›",
      "Vineeth Madhusudanan",
      "Product Manager, Statsig",
      "Power Analysis attached to Experiments",
      "Power Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.",
      "This feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.",
      "Experiment Setup Screen",
      "Starting Power Analysis from an Experiment",
      "10/25/2024",
      "Permalink ›",
      "Craig Sexauer",
      "Data Scientist, Statsig",
      "🥇 First-Value metrics",
      "Alongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.",
      "Learn more in",
      "our documentation",
      "Join the #1 experimentation community",
      "Connect with like-minded product leaders, data scientists,",
      "and engineers to share the latest in product experimentation.",
      "Join Community",
      "Older updates",
      "Try Statsig Today",
      "Get started for free. Add your whole team!",
      "Sign up for Free",
      "Test Drive Now",
      "Why the best build with us",
      "Testimonials",
      "At OpenAI, we want to iterate as fast as possible.",
      "Statsig enables us to grow, scale, and learn efficiently",
      ". Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.",
      "OpenAI",
      "Dave Cummings",
      "Engineering Manager, ChatGPT",
      "More stories",
      "Brex's mission is to help businesses move fast.",
      "Statsig is now helping our engineers move fast",
      ". It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.",
      "Brex",
      "Karandeep Anand",
      "President",
      "More stories",
      "At Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.",
      "Statsig's experimentation platform enables both this speed and learning for us",
      ".",
      "Notion",
      "Mengying Li",
      "Data Science Manager",
      "More stories",
      "We evaluated Optimizely, LaunchDarkly, Split, and Eppo, but",
      "ultimately selected Statsig due to its comprehensive end-to-end integration",
      ". We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.",
      "SoundCloud",
      "Don Browning",
      "SVP, Data & Platform Engineering",
      "More stories",
      "We only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.",
      "We are definitely heading in the right direction with Statsig",
      ".",
      "Ancestry",
      "Partha Sarathi",
      "Director of Engineering",
      "More stories",
      "const vocLength = 5;",
      "let prevSelectedVoiceIndex = vocLength - 1;",
      "function _selectVoice(index) {",
      "if (index === prevSelectedVoiceIndex) {",
      "return;",
      "}",
      "const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;",
      "const voiceId = `voiceHeading${index}`;",
      "$d(prevVoiceId).classList.remove('selected');",
      "$d(voiceId).classList.add('selected');",
      "const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;",
      "const voiceContentId = `voiceContent${index}`;",
      "$d(prevVoiceContentId).style.opacity = 0;",
      "$d(prevVoiceContentId).classList.remove('onTop');",
      "$d(voiceContentId).style.opacity = 1;",
      "$d(voiceContentId).classList.add('onTop');",
      "prevSelectedVoiceIndex = index;",
      "}",
      "_selectVoice(0);",
      "We use cookies to ensure you get the best experience on our website.",
      "Privacy Policy",
      "Got it!",
      "id=\"cookieConsent\"",
      "id=\"pageContent\"",
      "id=\"pageBody\"",
      "const ccKey = '_cc_shown=1';",
      "window.__ccKey = ccKey;",
      "function setCookieConsent() {",
      "let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);",
      "document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;",
      "document.getElementById('cookieConsent').style.display = 'none';",
      "}",
      "Build. Measure. Ship. Confidently!",
      "Get Started",
      "Book a Live Demo",
      "Platform",
      "Feature Management",
      "Experimentation",
      "Data Warehouse",
      "Product Analytics",
      "Session Replay",
      "Web Analytics",
      "All Features",
      "Test Drive Now",
      "Why Statsig",
      "Product Observability",
      "How It Works",
      "Build vs Buy",
      "Pricing",
      "Customer Stories",
      "Testimonials",
      "Resources",
      "Docs",
      "Code",
      "Blog",
      "Product Updates",
      "<li>",
      "<a href=\"/kb\" data-event-value=\"kb\">",
      "Knowledge Base",
      "</a>",
      "</li>",
      "A/B Test Calculator",
      "Integrations",
      "Startup Program",
      "Join Community",
      "Events",
      "Feedback",
      "Status",
      "Company",
      "About Us",
      "Careers",
      "Pets",
      "Terms",
      "Privacy Policy",
      "Contact Us",
      "© 2024 Statsig, Inc.",
      "Hello from Bellevue, WA"
    ],
    "removed_content": [],
    "summary": "新增内容: Platform...",
    "url": "https://www.statsig.com/updates",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:40:36",
    "hash": "e934a4bb858f4dfb45bf6b0503b00d8e",
    "content": "关于 ABetterChoice\n​\nABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、\n实验分析\n和\nROI 仪表盘\n，以便于进行在线实验。\n入门指南\n​\n要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：\n创建项目\n：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。\nSDK 集成\n：集成 SDK 以快速开始收集洞察。\n数据连接\n：本指南介绍如何将您的数据源连接到 ABetterChoice。\n数据源与指标\n：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。\n开始您的第一个实验\n：本指南介绍如何在 ABetterChoice 中创建并运行实验。\n实验分析\n：本指南介绍如何解读 ABetterChoice 中的实验结果。\n如何使用 ROI 仪表盘\n：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/getting-started/overview",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:40:38",
    "hash": "e1b5ce3557f17232fbfe758ac92eee8e",
    "content": "Platform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPlatform\nResources\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\nPlatform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\n📢 Announcing the Statsig <> Azure AI Integration\n·\nLearn more\nfunction scrollCalendarContainer(pixels) {\n    $d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })\n  }\nProduct Updates\nNov 2024\n⏱️Experiment Compute Overview\n🏭 Autoscale on Snowflake WHN\n👁️ Single value views\n➕Cumulative Sum Rollups\n📐Retention Metrics on Statsig WHN\nOct 2024\n🎉 SCIM User Provisioning\n📋 Dynamic Configs Now Have Templates!\n⏱️WHN Compute Transparency\n⚡Inline Power Analysis\n🥇 First-Value metrics\n🔍 Focused Analysis with Top Group Limits\n🪵🪄 Log transforms\n⌚💰📊 Latest value metrics\n🧲 Group-by in Retention Analysis\n👯 Cohort analysis in all charts types\n📊 Cohort Analysis in Funnels\n🪜Funnels Now Support Up to 15 Steps\n🔗 Improved Segment Integration\n⏱️ 2x Funnel Performance Improvements\n💥 Cross-Environment Feature Gates View\n🚫 Metrics Update: Deprecating event_dau metric\nSep 2024\n🕧 Time to Complete Metrics\n⏳Funnels ++ on WHN\n📊 Distribution Analysis of Event Property Values\n% Percentage-Based Grouping\n⏰ Time Period Comparison in Funnels\n⏳ Funnels - Time to Convert Improvements\n⏸️ Pause Experiment Assignment\n🔔 Email Notification Preferences\n👤 ID Resolution++\nAug 2024\n🎛️ Dashboard Filters\n🧠 Experiment Knowledge Base\n🎓 Meta Analysis : August Release\n🧲 Retention Overhaul\n✨🛤️✨User Journeys Overhaul\n📅 Expanded Chart Granularities and MAU support\n📧 Dashboard PDF Export\n🚀❤️📊 Statsig <3 Funnels\n🕒 Session Analytics Private Beta\n📋 Custom Experiment Checklist\n📈 WHN Product Analytics\n🤖 Bot Filtering\n🤳 Parameter Stores\nJul 2024\n📊 Benjamini-Hochberg\n🔗 Combine Events in Funnel Steps\n🔍 First-Time Filters in Funnels\n🌊 Session Streams\n⌨️ Keyboard Navigation\n📊 Outlier Detection\n💾 Reusable Cohorts\n🧢 Capped Metrics (WHN)\n🕵 Differential Impact Detection\n💄 New look and feel on Statsig\n👩‍💻 Statsig Managed API Proxy\n🏠 New Home Experience\n🧮 Improved Formula Support\n🙋‍♀️ User Management v2\n🎓 Meta Analysis : July release\nJun 2024\n🌓 One Sided Tests\n♻️ WHN Statsig Table Lifecycle\n✨Dashboard Templates\n🧭 Updated navigation\n👩🏼‍💻 Statsig CLI (”Siggy”)\n📍 Advanced Local Metrics - WHN\n🔽 Pulse Lift View Selector\nℹ️ Metric Detail Cards\n💻 New Suite of Javascript SDKs\n🎓 Meta-analysis : June Release\nMay 2024\n⚡WHN SDK events now hourly\n💾 Saved Queries\n💻 Web Analytics\n🎯 Inline Targeting Criteria\n🎂 Stratified Sampling\n📃 Tables as Metric Sources\n🥷🏼 Statsig ID Resolver\n🎯 Multi-Event Cohorts\n🫀 SDK Health Visibility\n🔽 Funnels 2.0\nApr 2024\n🎯 Assignment Filtering on WHN\n📏 Threshold Metrics on WHN\n🧢 Capped Metrics\n⏯️ Statsig Session Replay Beta\n👥 Teams Configuration Settings\n🆕 Refreshing Pulse (Scorecards)\n📍Local Metrics on WHN\n📋 Schemas for Dynamic Configs\n💬 Comments in Dynamic Configs\n🧮 More Metric Flexibility on WHN\nMar 2024\n🌸 Dashboards Spring Cleaning\n📤 Templates\n🍯 Persistent Assignment\n🚨 Alerts++\n% Percentile Metrics\n🥽 visionOS support\n🔍 Diagnostics 2.0\n🧮 New Metric Types on WHN\n🤼 Teams\nFeb 2024\nSlice by Feature Gate group in Metrics Explorer\n🚫 Read Only Metric Definitions\nSlice Experiments by User Dimension in Metrics Explorer\nUser Journeys (Beta)\n👤 Anonymous -> User ID\n🕒 Scheduled Reloads\n🤖 Statbot (in Console)\n✅ Verified Metrics\nJan 2024\nEvent-Based Cohorts in Metrics Explorer\nSlice by Experiment Group in Metrics Explorer\nNew Group Assignment Health Check\nDec 2023\nNew Year, New (& Improved) Console\nNew & Improved Custom Queries\nNov 2023\nEnhanced Formulas in Metrics Explorer\n📣 Interactive Experiment Summaries\nImproved Power Analysis Calculator\nOct 2023\n📊 Improving Charts in Dashboards\nExperiment Summary PDF\nSep 2023\nNew Experiment Scorecard (Pulse) Views\n🪦Metric Archival\nAug 2023\n📝 Smart Scorecard Limits\n🚨Experiment Policy\n👩‍💻 Github Code References\nNew & Improved Experiment Setup Checklist\nBetter Experiment Defaults\nJul 2023\nAnalytics : Custom retention reports\nExperiment on the edge with Fastly\nBayesian Analysis for Experiments\n📊Bar Charts in Metrics Explorer\nStatsig Warehouse Native\nJun 2023\nCustom roles for Role Based Access Control\n📈 Metrics Explorer\nFaster Users Tab to troubleshoot in production\nMay 2023\nTargeting on Holdouts\n⌛ 90-day Pulse expiration\nCloning Metrics\nApr 2023\nFaster Pulse, Environments in Overrides, Experiment Duration by Exposures\nManual assignment for Stratified Sampling\nWarehouse ingestion tab makeover\nMar 2023\n📊 Explore metrics outside just an experiment\n🧮 Including targeting gates in your power calculations\nLeft navigation bar auto-collapse, permanent and stale gates\nMetric Alerts\nComposite Sums, Pass Rate Filter, Permanent Gates, and More\nFeb 2023\nFlexible Environment Configuration and Metrics Directionality\nDatadog Trigger Integration\nManaging Feature Gate Lifecycle, Including Cleanup\nJan 2023\nMetrics Archival, Deletion and More!\nDec 2022\nHistorical Pulse Results, Following Tags, and Custom Metrics Improvements\nData Warehouse Ingestion\nMonitoring Metrics & Explore in Feature Gates\nNov 2022\nNew Slack Integration\nOct 2022\nv1 Dashboards, Discussion Tags, and Advanced Search\nDeeper Amplitude Integration\nNew Sequential Testing Capabilities\nSep 2022\nExperiment Setup Configuration UX, Automated A/A Test Reports, and more\nBroader ID Support in Autotune and Downloadable Events Explorer Results\nHome Tab Updates\nSnowflake, Redshift, BigQuery Data Warehouse Support\nAug 2022\nExplore Tab, Search Improvements, and More\nReviews at Various Levels, Metrics Bulk Management, New Users Tab, and More\nJul 2022\nImages for Experiment Groups\nMetrics Logstream and Experiment Checklist\nExperiment Scorecard and CUPED\nJun 2022\nCustom Metrics, Filtered Search, and more\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nExperiment Compute Summary\nFollowing up from the Statsig\nproject level compute summary\n, we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to\noptimize costs\n.\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nAutoscaling on Snowflake (Warehouse Native)\nYou can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to\nSettings > Project > Data Connection,\nand select\nSet up additional Warehouses\n.\nWhen you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.\nWe have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!\n11/20/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n👁️ Updated\nSingle Value Views in Metric Drilldown and Dashboards\nUse Case\nWhen you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.\nWhy It’s Important\nSingle Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.\nThe Feature: What It Does\nYou can now directly select\nSingle Value\nas a widget type when adding items to your\nDashboards\n, making it easier to showcase key metrics prominently without additional configuration.\nIn addition, within\nMetric Drilldown\n, you can choose the Single Value view to display your metric as a headline figure. This feature offers:\nLatest Full Data Point:\nView the most recent complete data point (e.g., yesterday’s total sales or user activities).\nOverall Value for Time Range:\nSee the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.\nComparison Options:\nSelect a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.\nBy incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.\n11/5/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n➕Cumulative Sum Rollups in Metric Drilldown\nUse Case\nWhen analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:\n“How many times has this feature ever been used?\n“How many distinct people have ever used this feature?”\n“What is the total revenue generated up to this point?”\nWhy It’s Important\nViewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.\nThe Feature: What It Does\nIn\nMetric Drilldown\n, after selecting an event and choosing an aggregation method—such as\nEvent Count\n,\nUniques\n,\nAverage of Property Value\n, etc.—you can now apply the\nCumulative Sum\noption to your results. This feature accumulates your selected metric over time, providing a running total in your charts.\nWhen the metric aggregation is set to\nUniques\n, you have two options for calculating the cumulative sum:\nDistinct Uniques\nWhat it does\n: Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.\nUse Case\n: Answers\n“How many distinct people have ever used this feature?”\nby providing a deduplicated cumulative count.\nTotal Uniques\nWhat it does\n: Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.\nUse Case\n: Helps you understand\n“What is the total number of unique user engagements over time, including repeat users?”\nThis provides insight into recurring user activity across different periods.\nFor other aggregation types:\nEvent Count\n: The cumulative sum shows the total number of events over time, helping you track overall engagement.\nAverage of Property Value\n: Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.\nSum of Property Value:\nAccumulates the sum of a chosen property value from your events, useful for questions like \"\nWhat is the total revenue generated up to this point?\"\nor\n“What is the cumulative sum of this property over time?”\nby providing the total accumulated value.\nBy enabling the\nCumulative Sum\noption, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.\n11/4/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\nStatsig Cloud launched with user accounting metrics -\nincluding retention\n. We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!\nRetention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.\nThis allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.\nThis class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo\nused retention metrics\nto measure and drive long-term install and revenue growth.\nCheck out the\ndocs\n, and try it out in Warehouse Native today!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nIntroducing Open-Beta SCIM Support on Statsig\nWe're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,\nStatsig Docs\n.\nThis is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!\nKey Features\nUser Provisioning\n: Automatically create and manage user accounts in Statsig based on Okta identities\nRole Assignment\n: Easily assign and manage user roles through Okta, ensuring consistent access controls\nBenefits:\nStreamlined User Management\n: Simplify the onboarding process with automated account creation and updates.\nEnhanced Security\n: Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.\nImproved Efficiency\n: Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.\nScalability\n: Easily manage user identities as your organization grows, without the hassle of manual interventions.\nThis enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nExtending Templates to Dynamic Configs\nOver the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!\nQuick context on Dynamic Configs\nDynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.\nTemplates\nTemplates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via\nOrganization Settings\nand\nRole-based Access Controls\n) or at the\nTeam-level\n.\n10/29/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nWarehouse Native Compute Transparency Dashboard\nStatsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.\nCommon customers we've designed the dashboard to be able to address include\nWhat Metric Sources take the most compute time (useful to focus optimization effort here; see tips\nhere\n)\nWhat is the split of compute time between full loads vs incremental loads vs custom queries?\nHow is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)\nYou can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview\nThis is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.\n10/25/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nPower Analysis attached to Experiments\nPower Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.\nThis feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.\nExperiment Setup Screen\nStarting Power Analysis from an Experiment\n10/25/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\n🥇 First-Value metrics\nAlongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.\nLearn more in\nour documentation\nJoin the #1 experimentation community\nConnect with like-minded product leaders, data scientists, \n      and engineers to share the latest in product experimentation.\nJoin Community\nOlder updates\nTry Statsig Today\nGet started for free. Add your whole team!\nSign up for Free\nTest Drive Now\nWhy the best build with us\nTestimonials\nAt OpenAI, we want to iterate as fast as possible.\nStatsig enables us to grow, scale, and learn efficiently\n. Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.\nOpenAI\nDave Cummings\nEngineering Manager, ChatGPT\nMore stories\nBrex's mission is to help businesses move fast.\nStatsig is now helping our engineers move fast\n. It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.\nBrex\nKarandeep Anand\nPresident\nMore stories\nAt Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.\nStatsig's experimentation platform enables both this speed and learning for us\n.\nNotion\nMengying Li\nData Science Manager\nMore stories\nWe evaluated Optimizely, LaunchDarkly, Split, and Eppo, but\nultimately selected Statsig due to its comprehensive end-to-end integration\n. We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.\nSoundCloud\nDon Browning\nSVP, Data & Platform Engineering\nMore stories\nWe only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.\nWe are definitely heading in the right direction with Statsig\n.\nAncestry\nPartha Sarathi\nDirector of Engineering\nMore stories\nconst vocLength = 5;\n  let prevSelectedVoiceIndex = vocLength - 1;\n  function _selectVoice(index) {\n    if (index === prevSelectedVoiceIndex) {\n      return;\n    }\n    const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;\n    const voiceId = `voiceHeading${index}`;\n    $d(prevVoiceId).classList.remove('selected');\n    $d(voiceId).classList.add('selected');\n\n    const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;\n    const voiceContentId = `voiceContent${index}`;\n    $d(prevVoiceContentId).style.opacity = 0;\n    $d(prevVoiceContentId).classList.remove('onTop');\n    $d(voiceContentId).style.opacity = 1;\n    $d(voiceContentId).classList.add('onTop');\n\n    prevSelectedVoiceIndex = index;\n  }\n  _selectVoice(0);\nWe use cookies to ensure you get the best experience on our website.\nPrivacy Policy\nGot it!\nid=\"cookieConsent\"\nid=\"pageContent\"\nid=\"pageBody\"\nconst ccKey = '_cc_shown=1';\n  window.__ccKey = ccKey;\n  function setCookieConsent() {\n    let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);\n    document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;\n    document.getElementById('cookieConsent').style.display = 'none';\n  }\nBuild. Measure. Ship. Confidently!\nGet Started\nBook a Live Demo\nPlatform\nFeature Management\nExperimentation\nData Warehouse\nProduct Analytics\nSession Replay\nWeb Analytics\nAll Features\nTest Drive Now\nWhy Statsig\nProduct Observability\nHow It Works\nBuild vs Buy\nPricing\nCustomer Stories\nTestimonials\nResources\nDocs\nCode\nBlog\nProduct Updates\n<li>\n                <a href=\"/kb\" data-event-value=\"kb\">\n                  Knowledge Base\n                </a>\n              </li>\nA/B Test Calculator\nIntegrations\nStartup Program\nJoin Community\nEvents\nFeedback\nStatus\nCompany\nAbout Us\nCareers\nPets\nTerms\nPrivacy Policy\nContact Us\n© 2024 Statsig, Inc.\nHello from Bellevue, WA\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://www.statsig.com/updates",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:41:15",
    "hash": "e934a4bb858f4dfb45bf6b0503b00d8e",
    "content": "关于 ABetterChoice\n​\nABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、\n实验分析\n和\nROI 仪表盘\n，以便于进行在线实验。\n入门指南\n​\n要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：\n创建项目\n：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。\nSDK 集成\n：集成 SDK 以快速开始收集洞察。\n数据连接\n：本指南介绍如何将您的数据源连接到 ABetterChoice。\n数据源与指标\n：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。\n开始您的第一个实验\n：本指南介绍如何在 ABetterChoice 中创建并运行实验。\n实验分析\n：本指南介绍如何解读 ABetterChoice 中的实验结果。\n如何使用 ROI 仪表盘\n：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/getting-started/overview",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:41:17",
    "hash": "e1b5ce3557f17232fbfe758ac92eee8e",
    "content": "Platform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPlatform\nResources\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\nPlatform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\n📢 Announcing the Statsig <> Azure AI Integration\n·\nLearn more\nfunction scrollCalendarContainer(pixels) {\n    $d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })\n  }\nProduct Updates\nNov 2024\n⏱️Experiment Compute Overview\n🏭 Autoscale on Snowflake WHN\n👁️ Single value views\n➕Cumulative Sum Rollups\n📐Retention Metrics on Statsig WHN\nOct 2024\n🎉 SCIM User Provisioning\n📋 Dynamic Configs Now Have Templates!\n⏱️WHN Compute Transparency\n⚡Inline Power Analysis\n🥇 First-Value metrics\n🔍 Focused Analysis with Top Group Limits\n🪵🪄 Log transforms\n⌚💰📊 Latest value metrics\n🧲 Group-by in Retention Analysis\n👯 Cohort analysis in all charts types\n📊 Cohort Analysis in Funnels\n🪜Funnels Now Support Up to 15 Steps\n🔗 Improved Segment Integration\n⏱️ 2x Funnel Performance Improvements\n💥 Cross-Environment Feature Gates View\n🚫 Metrics Update: Deprecating event_dau metric\nSep 2024\n🕧 Time to Complete Metrics\n⏳Funnels ++ on WHN\n📊 Distribution Analysis of Event Property Values\n% Percentage-Based Grouping\n⏰ Time Period Comparison in Funnels\n⏳ Funnels - Time to Convert Improvements\n⏸️ Pause Experiment Assignment\n🔔 Email Notification Preferences\n👤 ID Resolution++\nAug 2024\n🎛️ Dashboard Filters\n🧠 Experiment Knowledge Base\n🎓 Meta Analysis : August Release\n🧲 Retention Overhaul\n✨🛤️✨User Journeys Overhaul\n📅 Expanded Chart Granularities and MAU support\n📧 Dashboard PDF Export\n🚀❤️📊 Statsig <3 Funnels\n🕒 Session Analytics Private Beta\n📋 Custom Experiment Checklist\n📈 WHN Product Analytics\n🤖 Bot Filtering\n🤳 Parameter Stores\nJul 2024\n📊 Benjamini-Hochberg\n🔗 Combine Events in Funnel Steps\n🔍 First-Time Filters in Funnels\n🌊 Session Streams\n⌨️ Keyboard Navigation\n📊 Outlier Detection\n💾 Reusable Cohorts\n🧢 Capped Metrics (WHN)\n🕵 Differential Impact Detection\n💄 New look and feel on Statsig\n👩‍💻 Statsig Managed API Proxy\n🏠 New Home Experience\n🧮 Improved Formula Support\n🙋‍♀️ User Management v2\n🎓 Meta Analysis : July release\nJun 2024\n🌓 One Sided Tests\n♻️ WHN Statsig Table Lifecycle\n✨Dashboard Templates\n🧭 Updated navigation\n👩🏼‍💻 Statsig CLI (”Siggy”)\n📍 Advanced Local Metrics - WHN\n🔽 Pulse Lift View Selector\nℹ️ Metric Detail Cards\n💻 New Suite of Javascript SDKs\n🎓 Meta-analysis : June Release\nMay 2024\n⚡WHN SDK events now hourly\n💾 Saved Queries\n💻 Web Analytics\n🎯 Inline Targeting Criteria\n🎂 Stratified Sampling\n📃 Tables as Metric Sources\n🥷🏼 Statsig ID Resolver\n🎯 Multi-Event Cohorts\n🫀 SDK Health Visibility\n🔽 Funnels 2.0\nApr 2024\n🎯 Assignment Filtering on WHN\n📏 Threshold Metrics on WHN\n🧢 Capped Metrics\n⏯️ Statsig Session Replay Beta\n👥 Teams Configuration Settings\n🆕 Refreshing Pulse (Scorecards)\n📍Local Metrics on WHN\n📋 Schemas for Dynamic Configs\n💬 Comments in Dynamic Configs\n🧮 More Metric Flexibility on WHN\nMar 2024\n🌸 Dashboards Spring Cleaning\n📤 Templates\n🍯 Persistent Assignment\n🚨 Alerts++\n% Percentile Metrics\n🥽 visionOS support\n🔍 Diagnostics 2.0\n🧮 New Metric Types on WHN\n🤼 Teams\nFeb 2024\nSlice by Feature Gate group in Metrics Explorer\n🚫 Read Only Metric Definitions\nSlice Experiments by User Dimension in Metrics Explorer\nUser Journeys (Beta)\n👤 Anonymous -> User ID\n🕒 Scheduled Reloads\n🤖 Statbot (in Console)\n✅ Verified Metrics\nJan 2024\nEvent-Based Cohorts in Metrics Explorer\nSlice by Experiment Group in Metrics Explorer\nNew Group Assignment Health Check\nDec 2023\nNew Year, New (& Improved) Console\nNew & Improved Custom Queries\nNov 2023\nEnhanced Formulas in Metrics Explorer\n📣 Interactive Experiment Summaries\nImproved Power Analysis Calculator\nOct 2023\n📊 Improving Charts in Dashboards\nExperiment Summary PDF\nSep 2023\nNew Experiment Scorecard (Pulse) Views\n🪦Metric Archival\nAug 2023\n📝 Smart Scorecard Limits\n🚨Experiment Policy\n👩‍💻 Github Code References\nNew & Improved Experiment Setup Checklist\nBetter Experiment Defaults\nJul 2023\nAnalytics : Custom retention reports\nExperiment on the edge with Fastly\nBayesian Analysis for Experiments\n📊Bar Charts in Metrics Explorer\nStatsig Warehouse Native\nJun 2023\nCustom roles for Role Based Access Control\n📈 Metrics Explorer\nFaster Users Tab to troubleshoot in production\nMay 2023\nTargeting on Holdouts\n⌛ 90-day Pulse expiration\nCloning Metrics\nApr 2023\nFaster Pulse, Environments in Overrides, Experiment Duration by Exposures\nManual assignment for Stratified Sampling\nWarehouse ingestion tab makeover\nMar 2023\n📊 Explore metrics outside just an experiment\n🧮 Including targeting gates in your power calculations\nLeft navigation bar auto-collapse, permanent and stale gates\nMetric Alerts\nComposite Sums, Pass Rate Filter, Permanent Gates, and More\nFeb 2023\nFlexible Environment Configuration and Metrics Directionality\nDatadog Trigger Integration\nManaging Feature Gate Lifecycle, Including Cleanup\nJan 2023\nMetrics Archival, Deletion and More!\nDec 2022\nHistorical Pulse Results, Following Tags, and Custom Metrics Improvements\nData Warehouse Ingestion\nMonitoring Metrics & Explore in Feature Gates\nNov 2022\nNew Slack Integration\nOct 2022\nv1 Dashboards, Discussion Tags, and Advanced Search\nDeeper Amplitude Integration\nNew Sequential Testing Capabilities\nSep 2022\nExperiment Setup Configuration UX, Automated A/A Test Reports, and more\nBroader ID Support in Autotune and Downloadable Events Explorer Results\nHome Tab Updates\nSnowflake, Redshift, BigQuery Data Warehouse Support\nAug 2022\nExplore Tab, Search Improvements, and More\nReviews at Various Levels, Metrics Bulk Management, New Users Tab, and More\nJul 2022\nImages for Experiment Groups\nMetrics Logstream and Experiment Checklist\nExperiment Scorecard and CUPED\nJun 2022\nCustom Metrics, Filtered Search, and more\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nExperiment Compute Summary\nFollowing up from the Statsig\nproject level compute summary\n, we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to\noptimize costs\n.\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nAutoscaling on Snowflake (Warehouse Native)\nYou can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to\nSettings > Project > Data Connection,\nand select\nSet up additional Warehouses\n.\nWhen you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.\nWe have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!\n11/20/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n👁️ Updated\nSingle Value Views in Metric Drilldown and Dashboards\nUse Case\nWhen you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.\nWhy It’s Important\nSingle Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.\nThe Feature: What It Does\nYou can now directly select\nSingle Value\nas a widget type when adding items to your\nDashboards\n, making it easier to showcase key metrics prominently without additional configuration.\nIn addition, within\nMetric Drilldown\n, you can choose the Single Value view to display your metric as a headline figure. This feature offers:\nLatest Full Data Point:\nView the most recent complete data point (e.g., yesterday’s total sales or user activities).\nOverall Value for Time Range:\nSee the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.\nComparison Options:\nSelect a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.\nBy incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.\n11/5/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n➕Cumulative Sum Rollups in Metric Drilldown\nUse Case\nWhen analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:\n“How many times has this feature ever been used?\n“How many distinct people have ever used this feature?”\n“What is the total revenue generated up to this point?”\nWhy It’s Important\nViewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.\nThe Feature: What It Does\nIn\nMetric Drilldown\n, after selecting an event and choosing an aggregation method—such as\nEvent Count\n,\nUniques\n,\nAverage of Property Value\n, etc.—you can now apply the\nCumulative Sum\noption to your results. This feature accumulates your selected metric over time, providing a running total in your charts.\nWhen the metric aggregation is set to\nUniques\n, you have two options for calculating the cumulative sum:\nDistinct Uniques\nWhat it does\n: Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.\nUse Case\n: Answers\n“How many distinct people have ever used this feature?”\nby providing a deduplicated cumulative count.\nTotal Uniques\nWhat it does\n: Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.\nUse Case\n: Helps you understand\n“What is the total number of unique user engagements over time, including repeat users?”\nThis provides insight into recurring user activity across different periods.\nFor other aggregation types:\nEvent Count\n: The cumulative sum shows the total number of events over time, helping you track overall engagement.\nAverage of Property Value\n: Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.\nSum of Property Value:\nAccumulates the sum of a chosen property value from your events, useful for questions like \"\nWhat is the total revenue generated up to this point?\"\nor\n“What is the cumulative sum of this property over time?”\nby providing the total accumulated value.\nBy enabling the\nCumulative Sum\noption, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.\n11/4/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\nStatsig Cloud launched with user accounting metrics -\nincluding retention\n. We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!\nRetention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.\nThis allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.\nThis class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo\nused retention metrics\nto measure and drive long-term install and revenue growth.\nCheck out the\ndocs\n, and try it out in Warehouse Native today!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nIntroducing Open-Beta SCIM Support on Statsig\nWe're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,\nStatsig Docs\n.\nThis is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!\nKey Features\nUser Provisioning\n: Automatically create and manage user accounts in Statsig based on Okta identities\nRole Assignment\n: Easily assign and manage user roles through Okta, ensuring consistent access controls\nBenefits:\nStreamlined User Management\n: Simplify the onboarding process with automated account creation and updates.\nEnhanced Security\n: Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.\nImproved Efficiency\n: Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.\nScalability\n: Easily manage user identities as your organization grows, without the hassle of manual interventions.\nThis enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nExtending Templates to Dynamic Configs\nOver the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!\nQuick context on Dynamic Configs\nDynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.\nTemplates\nTemplates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via\nOrganization Settings\nand\nRole-based Access Controls\n) or at the\nTeam-level\n.\n10/29/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nWarehouse Native Compute Transparency Dashboard\nStatsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.\nCommon customers we've designed the dashboard to be able to address include\nWhat Metric Sources take the most compute time (useful to focus optimization effort here; see tips\nhere\n)\nWhat is the split of compute time between full loads vs incremental loads vs custom queries?\nHow is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)\nYou can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview\nThis is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.\n10/25/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nPower Analysis attached to Experiments\nPower Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.\nThis feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.\nExperiment Setup Screen\nStarting Power Analysis from an Experiment\n10/25/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\n🥇 First-Value metrics\nAlongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.\nLearn more in\nour documentation\nJoin the #1 experimentation community\nConnect with like-minded product leaders, data scientists, \n      and engineers to share the latest in product experimentation.\nJoin Community\nOlder updates\nTry Statsig Today\nGet started for free. Add your whole team!\nSign up for Free\nTest Drive Now\nWhy the best build with us\nTestimonials\nAt OpenAI, we want to iterate as fast as possible.\nStatsig enables us to grow, scale, and learn efficiently\n. Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.\nOpenAI\nDave Cummings\nEngineering Manager, ChatGPT\nMore stories\nBrex's mission is to help businesses move fast.\nStatsig is now helping our engineers move fast\n. It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.\nBrex\nKarandeep Anand\nPresident\nMore stories\nAt Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.\nStatsig's experimentation platform enables both this speed and learning for us\n.\nNotion\nMengying Li\nData Science Manager\nMore stories\nWe evaluated Optimizely, LaunchDarkly, Split, and Eppo, but\nultimately selected Statsig due to its comprehensive end-to-end integration\n. We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.\nSoundCloud\nDon Browning\nSVP, Data & Platform Engineering\nMore stories\nWe only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.\nWe are definitely heading in the right direction with Statsig\n.\nAncestry\nPartha Sarathi\nDirector of Engineering\nMore stories\nconst vocLength = 5;\n  let prevSelectedVoiceIndex = vocLength - 1;\n  function _selectVoice(index) {\n    if (index === prevSelectedVoiceIndex) {\n      return;\n    }\n    const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;\n    const voiceId = `voiceHeading${index}`;\n    $d(prevVoiceId).classList.remove('selected');\n    $d(voiceId).classList.add('selected');\n\n    const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;\n    const voiceContentId = `voiceContent${index}`;\n    $d(prevVoiceContentId).style.opacity = 0;\n    $d(prevVoiceContentId).classList.remove('onTop');\n    $d(voiceContentId).style.opacity = 1;\n    $d(voiceContentId).classList.add('onTop');\n\n    prevSelectedVoiceIndex = index;\n  }\n  _selectVoice(0);\nWe use cookies to ensure you get the best experience on our website.\nPrivacy Policy\nGot it!\nid=\"cookieConsent\"\nid=\"pageContent\"\nid=\"pageBody\"\nconst ccKey = '_cc_shown=1';\n  window.__ccKey = ccKey;\n  function setCookieConsent() {\n    let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);\n    document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;\n    document.getElementById('cookieConsent').style.display = 'none';\n  }\nBuild. Measure. Ship. Confidently!\nGet Started\nBook a Live Demo\nPlatform\nFeature Management\nExperimentation\nData Warehouse\nProduct Analytics\nSession Replay\nWeb Analytics\nAll Features\nTest Drive Now\nWhy Statsig\nProduct Observability\nHow It Works\nBuild vs Buy\nPricing\nCustomer Stories\nTestimonials\nResources\nDocs\nCode\nBlog\nProduct Updates\n<li>\n                <a href=\"/kb\" data-event-value=\"kb\">\n                  Knowledge Base\n                </a>\n              </li>\nA/B Test Calculator\nIntegrations\nStartup Program\nJoin Community\nEvents\nFeedback\nStatus\nCompany\nAbout Us\nCareers\nPets\nTerms\nPrivacy Policy\nContact Us\n© 2024 Statsig, Inc.\nHello from Bellevue, WA\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://www.statsig.com/updates",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:43:25",
    "hash": "e934a4bb858f4dfb45bf6b0503b00d8e",
    "content": "关于 ABetterChoice\n​\nABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、\n实验分析\n和\nROI 仪表盘\n，以便于进行在线实验。\n入门指南\n​\n要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：\n创建项目\n：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。\nSDK 集成\n：集成 SDK 以快速开始收集洞察。\n数据连接\n：本指南介绍如何将您的数据源连接到 ABetterChoice。\n数据源与指标\n：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。\n开始您的第一个实验\n：本指南介绍如何在 ABetterChoice 中创建并运行实验。\n实验分析\n：本指南介绍如何解读 ABetterChoice 中的实验结果。\n如何使用 ROI 仪表盘\n：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/getting-started/overview",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:43:27",
    "hash": "e1b5ce3557f17232fbfe758ac92eee8e",
    "content": "Platform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPlatform\nResources\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\nPlatform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\n📢 Announcing the Statsig <> Azure AI Integration\n·\nLearn more\nfunction scrollCalendarContainer(pixels) {\n    $d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })\n  }\nProduct Updates\nNov 2024\n⏱️Experiment Compute Overview\n🏭 Autoscale on Snowflake WHN\n👁️ Single value views\n➕Cumulative Sum Rollups\n📐Retention Metrics on Statsig WHN\nOct 2024\n🎉 SCIM User Provisioning\n📋 Dynamic Configs Now Have Templates!\n⏱️WHN Compute Transparency\n⚡Inline Power Analysis\n🥇 First-Value metrics\n🔍 Focused Analysis with Top Group Limits\n🪵🪄 Log transforms\n⌚💰📊 Latest value metrics\n🧲 Group-by in Retention Analysis\n👯 Cohort analysis in all charts types\n📊 Cohort Analysis in Funnels\n🪜Funnels Now Support Up to 15 Steps\n🔗 Improved Segment Integration\n⏱️ 2x Funnel Performance Improvements\n💥 Cross-Environment Feature Gates View\n🚫 Metrics Update: Deprecating event_dau metric\nSep 2024\n🕧 Time to Complete Metrics\n⏳Funnels ++ on WHN\n📊 Distribution Analysis of Event Property Values\n% Percentage-Based Grouping\n⏰ Time Period Comparison in Funnels\n⏳ Funnels - Time to Convert Improvements\n⏸️ Pause Experiment Assignment\n🔔 Email Notification Preferences\n👤 ID Resolution++\nAug 2024\n🎛️ Dashboard Filters\n🧠 Experiment Knowledge Base\n🎓 Meta Analysis : August Release\n🧲 Retention Overhaul\n✨🛤️✨User Journeys Overhaul\n📅 Expanded Chart Granularities and MAU support\n📧 Dashboard PDF Export\n🚀❤️📊 Statsig <3 Funnels\n🕒 Session Analytics Private Beta\n📋 Custom Experiment Checklist\n📈 WHN Product Analytics\n🤖 Bot Filtering\n🤳 Parameter Stores\nJul 2024\n📊 Benjamini-Hochberg\n🔗 Combine Events in Funnel Steps\n🔍 First-Time Filters in Funnels\n🌊 Session Streams\n⌨️ Keyboard Navigation\n📊 Outlier Detection\n💾 Reusable Cohorts\n🧢 Capped Metrics (WHN)\n🕵 Differential Impact Detection\n💄 New look and feel on Statsig\n👩‍💻 Statsig Managed API Proxy\n🏠 New Home Experience\n🧮 Improved Formula Support\n🙋‍♀️ User Management v2\n🎓 Meta Analysis : July release\nJun 2024\n🌓 One Sided Tests\n♻️ WHN Statsig Table Lifecycle\n✨Dashboard Templates\n🧭 Updated navigation\n👩🏼‍💻 Statsig CLI (”Siggy”)\n📍 Advanced Local Metrics - WHN\n🔽 Pulse Lift View Selector\nℹ️ Metric Detail Cards\n💻 New Suite of Javascript SDKs\n🎓 Meta-analysis : June Release\nMay 2024\n⚡WHN SDK events now hourly\n💾 Saved Queries\n💻 Web Analytics\n🎯 Inline Targeting Criteria\n🎂 Stratified Sampling\n📃 Tables as Metric Sources\n🥷🏼 Statsig ID Resolver\n🎯 Multi-Event Cohorts\n🫀 SDK Health Visibility\n🔽 Funnels 2.0\nApr 2024\n🎯 Assignment Filtering on WHN\n📏 Threshold Metrics on WHN\n🧢 Capped Metrics\n⏯️ Statsig Session Replay Beta\n👥 Teams Configuration Settings\n🆕 Refreshing Pulse (Scorecards)\n📍Local Metrics on WHN\n📋 Schemas for Dynamic Configs\n💬 Comments in Dynamic Configs\n🧮 More Metric Flexibility on WHN\nMar 2024\n🌸 Dashboards Spring Cleaning\n📤 Templates\n🍯 Persistent Assignment\n🚨 Alerts++\n% Percentile Metrics\n🥽 visionOS support\n🔍 Diagnostics 2.0\n🧮 New Metric Types on WHN\n🤼 Teams\nFeb 2024\nSlice by Feature Gate group in Metrics Explorer\n🚫 Read Only Metric Definitions\nSlice Experiments by User Dimension in Metrics Explorer\nUser Journeys (Beta)\n👤 Anonymous -> User ID\n🕒 Scheduled Reloads\n🤖 Statbot (in Console)\n✅ Verified Metrics\nJan 2024\nEvent-Based Cohorts in Metrics Explorer\nSlice by Experiment Group in Metrics Explorer\nNew Group Assignment Health Check\nDec 2023\nNew Year, New (& Improved) Console\nNew & Improved Custom Queries\nNov 2023\nEnhanced Formulas in Metrics Explorer\n📣 Interactive Experiment Summaries\nImproved Power Analysis Calculator\nOct 2023\n📊 Improving Charts in Dashboards\nExperiment Summary PDF\nSep 2023\nNew Experiment Scorecard (Pulse) Views\n🪦Metric Archival\nAug 2023\n📝 Smart Scorecard Limits\n🚨Experiment Policy\n👩‍💻 Github Code References\nNew & Improved Experiment Setup Checklist\nBetter Experiment Defaults\nJul 2023\nAnalytics : Custom retention reports\nExperiment on the edge with Fastly\nBayesian Analysis for Experiments\n📊Bar Charts in Metrics Explorer\nStatsig Warehouse Native\nJun 2023\nCustom roles for Role Based Access Control\n📈 Metrics Explorer\nFaster Users Tab to troubleshoot in production\nMay 2023\nTargeting on Holdouts\n⌛ 90-day Pulse expiration\nCloning Metrics\nApr 2023\nFaster Pulse, Environments in Overrides, Experiment Duration by Exposures\nManual assignment for Stratified Sampling\nWarehouse ingestion tab makeover\nMar 2023\n📊 Explore metrics outside just an experiment\n🧮 Including targeting gates in your power calculations\nLeft navigation bar auto-collapse, permanent and stale gates\nMetric Alerts\nComposite Sums, Pass Rate Filter, Permanent Gates, and More\nFeb 2023\nFlexible Environment Configuration and Metrics Directionality\nDatadog Trigger Integration\nManaging Feature Gate Lifecycle, Including Cleanup\nJan 2023\nMetrics Archival, Deletion and More!\nDec 2022\nHistorical Pulse Results, Following Tags, and Custom Metrics Improvements\nData Warehouse Ingestion\nMonitoring Metrics & Explore in Feature Gates\nNov 2022\nNew Slack Integration\nOct 2022\nv1 Dashboards, Discussion Tags, and Advanced Search\nDeeper Amplitude Integration\nNew Sequential Testing Capabilities\nSep 2022\nExperiment Setup Configuration UX, Automated A/A Test Reports, and more\nBroader ID Support in Autotune and Downloadable Events Explorer Results\nHome Tab Updates\nSnowflake, Redshift, BigQuery Data Warehouse Support\nAug 2022\nExplore Tab, Search Improvements, and More\nReviews at Various Levels, Metrics Bulk Management, New Users Tab, and More\nJul 2022\nImages for Experiment Groups\nMetrics Logstream and Experiment Checklist\nExperiment Scorecard and CUPED\nJun 2022\nCustom Metrics, Filtered Search, and more\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nExperiment Compute Summary\nFollowing up from the Statsig\nproject level compute summary\n, we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to\noptimize costs\n.\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nAutoscaling on Snowflake (Warehouse Native)\nYou can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to\nSettings > Project > Data Connection,\nand select\nSet up additional Warehouses\n.\nWhen you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.\nWe have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!\n11/20/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n👁️ Updated\nSingle Value Views in Metric Drilldown and Dashboards\nUse Case\nWhen you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.\nWhy It’s Important\nSingle Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.\nThe Feature: What It Does\nYou can now directly select\nSingle Value\nas a widget type when adding items to your\nDashboards\n, making it easier to showcase key metrics prominently without additional configuration.\nIn addition, within\nMetric Drilldown\n, you can choose the Single Value view to display your metric as a headline figure. This feature offers:\nLatest Full Data Point:\nView the most recent complete data point (e.g., yesterday’s total sales or user activities).\nOverall Value for Time Range:\nSee the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.\nComparison Options:\nSelect a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.\nBy incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.\n11/5/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n➕Cumulative Sum Rollups in Metric Drilldown\nUse Case\nWhen analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:\n“How many times has this feature ever been used?\n“How many distinct people have ever used this feature?”\n“What is the total revenue generated up to this point?”\nWhy It’s Important\nViewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.\nThe Feature: What It Does\nIn\nMetric Drilldown\n, after selecting an event and choosing an aggregation method—such as\nEvent Count\n,\nUniques\n,\nAverage of Property Value\n, etc.—you can now apply the\nCumulative Sum\noption to your results. This feature accumulates your selected metric over time, providing a running total in your charts.\nWhen the metric aggregation is set to\nUniques\n, you have two options for calculating the cumulative sum:\nDistinct Uniques\nWhat it does\n: Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.\nUse Case\n: Answers\n“How many distinct people have ever used this feature?”\nby providing a deduplicated cumulative count.\nTotal Uniques\nWhat it does\n: Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.\nUse Case\n: Helps you understand\n“What is the total number of unique user engagements over time, including repeat users?”\nThis provides insight into recurring user activity across different periods.\nFor other aggregation types:\nEvent Count\n: The cumulative sum shows the total number of events over time, helping you track overall engagement.\nAverage of Property Value\n: Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.\nSum of Property Value:\nAccumulates the sum of a chosen property value from your events, useful for questions like \"\nWhat is the total revenue generated up to this point?\"\nor\n“What is the cumulative sum of this property over time?”\nby providing the total accumulated value.\nBy enabling the\nCumulative Sum\noption, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.\n11/4/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\nStatsig Cloud launched with user accounting metrics -\nincluding retention\n. We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!\nRetention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.\nThis allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.\nThis class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo\nused retention metrics\nto measure and drive long-term install and revenue growth.\nCheck out the\ndocs\n, and try it out in Warehouse Native today!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nIntroducing Open-Beta SCIM Support on Statsig\nWe're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,\nStatsig Docs\n.\nThis is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!\nKey Features\nUser Provisioning\n: Automatically create and manage user accounts in Statsig based on Okta identities\nRole Assignment\n: Easily assign and manage user roles through Okta, ensuring consistent access controls\nBenefits:\nStreamlined User Management\n: Simplify the onboarding process with automated account creation and updates.\nEnhanced Security\n: Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.\nImproved Efficiency\n: Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.\nScalability\n: Easily manage user identities as your organization grows, without the hassle of manual interventions.\nThis enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nExtending Templates to Dynamic Configs\nOver the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!\nQuick context on Dynamic Configs\nDynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.\nTemplates\nTemplates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via\nOrganization Settings\nand\nRole-based Access Controls\n) or at the\nTeam-level\n.\n10/29/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nWarehouse Native Compute Transparency Dashboard\nStatsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.\nCommon customers we've designed the dashboard to be able to address include\nWhat Metric Sources take the most compute time (useful to focus optimization effort here; see tips\nhere\n)\nWhat is the split of compute time between full loads vs incremental loads vs custom queries?\nHow is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)\nYou can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview\nThis is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.\n10/25/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nPower Analysis attached to Experiments\nPower Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.\nThis feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.\nExperiment Setup Screen\nStarting Power Analysis from an Experiment\n10/25/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\n🥇 First-Value metrics\nAlongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.\nLearn more in\nour documentation\nJoin the #1 experimentation community\nConnect with like-minded product leaders, data scientists, \n      and engineers to share the latest in product experimentation.\nJoin Community\nOlder updates\nTry Statsig Today\nGet started for free. Add your whole team!\nSign up for Free\nTest Drive Now\nWhy the best build with us\nTestimonials\nAt OpenAI, we want to iterate as fast as possible.\nStatsig enables us to grow, scale, and learn efficiently\n. Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.\nOpenAI\nDave Cummings\nEngineering Manager, ChatGPT\nMore stories\nBrex's mission is to help businesses move fast.\nStatsig is now helping our engineers move fast\n. It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.\nBrex\nKarandeep Anand\nPresident\nMore stories\nAt Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.\nStatsig's experimentation platform enables both this speed and learning for us\n.\nNotion\nMengying Li\nData Science Manager\nMore stories\nWe evaluated Optimizely, LaunchDarkly, Split, and Eppo, but\nultimately selected Statsig due to its comprehensive end-to-end integration\n. We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.\nSoundCloud\nDon Browning\nSVP, Data & Platform Engineering\nMore stories\nWe only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.\nWe are definitely heading in the right direction with Statsig\n.\nAncestry\nPartha Sarathi\nDirector of Engineering\nMore stories\nconst vocLength = 5;\n  let prevSelectedVoiceIndex = vocLength - 1;\n  function _selectVoice(index) {\n    if (index === prevSelectedVoiceIndex) {\n      return;\n    }\n    const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;\n    const voiceId = `voiceHeading${index}`;\n    $d(prevVoiceId).classList.remove('selected');\n    $d(voiceId).classList.add('selected');\n\n    const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;\n    const voiceContentId = `voiceContent${index}`;\n    $d(prevVoiceContentId).style.opacity = 0;\n    $d(prevVoiceContentId).classList.remove('onTop');\n    $d(voiceContentId).style.opacity = 1;\n    $d(voiceContentId).classList.add('onTop');\n\n    prevSelectedVoiceIndex = index;\n  }\n  _selectVoice(0);\nWe use cookies to ensure you get the best experience on our website.\nPrivacy Policy\nGot it!\nid=\"cookieConsent\"\nid=\"pageContent\"\nid=\"pageBody\"\nconst ccKey = '_cc_shown=1';\n  window.__ccKey = ccKey;\n  function setCookieConsent() {\n    let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);\n    document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;\n    document.getElementById('cookieConsent').style.display = 'none';\n  }\nBuild. Measure. Ship. Confidently!\nGet Started\nBook a Live Demo\nPlatform\nFeature Management\nExperimentation\nData Warehouse\nProduct Analytics\nSession Replay\nWeb Analytics\nAll Features\nTest Drive Now\nWhy Statsig\nProduct Observability\nHow It Works\nBuild vs Buy\nPricing\nCustomer Stories\nTestimonials\nResources\nDocs\nCode\nBlog\nProduct Updates\n<li>\n                <a href=\"/kb\" data-event-value=\"kb\">\n                  Knowledge Base\n                </a>\n              </li>\nA/B Test Calculator\nIntegrations\nStartup Program\nJoin Community\nEvents\nFeedback\nStatus\nCompany\nAbout Us\nCareers\nPets\nTerms\nPrivacy Policy\nContact Us\n© 2024 Statsig, Inc.\nHello from Bellevue, WA\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://www.statsig.com/updates",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:43:28",
    "hash": "63e816965bd712e6c9cddc9b0fb61480",
    "content": "Overview\nIntroduction\nGrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers.\nIt's great whether you're looking to just analyze experiment results or looking to make it easier to deploy code.\nGot questions?\nWe would love to help you get started with GrowthBook. You can\nmeet with us\nor\njoin our Slack\nQuick Links\n​\nHow it works\nLearn about what GrowthBook does and how it works\nQuick Start\nGet GrowthBook running in 10 minutes\nGet our open source guide to successful A/B testing and using GrowthBook\nThis guide outlines everything you need to know as you scale up experimentation at your company. It covers everything from foundational knowledge (“What is an A/B test?”) to advanced topics and common mistakes.\nOur Goals\n​\nCompanies invest thousands of hours building internal tools for feature flagging and experimentation (A/B testing). They do this to run these systems on their own infrastructure, utilize their own data, and ensure deep integration with their code.\nGrowthBook gives data, engineering, and product teams the power of a customizable platform without needing to build it themselves.\nWe believe that\nfeature flagging\nis the best way to release features, and\nA/B testing\nis the best way to measure their impact.\nWe believe A/B testing should sit on top of your\nexisting data and metrics\n, wherever they live and however they are defined.\nWe believe in\ndata transparency\n. See the SQL behind every query, export results as a Jupyter notebook, and view our\nstats engines on GitHub\n.\nWe are fanatical about\nperformance\n. Our\nSDKs\nare crazy fast, lightweight, and evaluate everything locally with no network requests.\nWe believe in\nopen source\n. GrowthBook is open source and free to use. You can run it on your own infrastructure or use our hosted version.\nWe believe in\nprivacy & security\n. We don't collect any data about your users, and you can run GrowthBook on your own infrastructure.\nWe believe good ideas come from everywhere. GrowthBook gives you feature flags, making it easy to\ntest everything\nand seamlessly integrate experimentation into your process.\nDocumentation\n​\nUse the menu or the\nPrevious\n/\nNext\nlinks to navigate these docs.\nJoin us on Slack\nif you need help, want to chat, or are thinking of a new feature. We're here to help—and to make GrowthBook even better.\nEdit this page\nNext\nHow it works\n",
    "has_update": true,
    "added_content": [
      "Overview",
      "Introduction",
      "GrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers.",
      "It's great whether you're looking to just analyze experiment results or looking to make it easier to deploy code.",
      "Got questions?",
      "We would love to help you get started with GrowthBook. You can",
      "meet with us",
      "or",
      "join our Slack",
      "Quick Links",
      "​",
      "How it works",
      "Learn about what GrowthBook does and how it works",
      "Quick Start",
      "Get GrowthBook running in 10 minutes",
      "Get our open source guide to successful A/B testing and using GrowthBook",
      "This guide outlines everything you need to know as you scale up experimentation at your company. It covers everything from foundational knowledge (“What is an A/B test?”) to advanced topics and common mistakes.",
      "Our Goals",
      "​",
      "Companies invest thousands of hours building internal tools for feature flagging and experimentation (A/B testing). They do this to run these systems on their own infrastructure, utilize their own data, and ensure deep integration with their code.",
      "GrowthBook gives data, engineering, and product teams the power of a customizable platform without needing to build it themselves.",
      "We believe that",
      "feature flagging",
      "is the best way to release features, and",
      "A/B testing",
      "is the best way to measure their impact.",
      "We believe A/B testing should sit on top of your",
      "existing data and metrics",
      ", wherever they live and however they are defined.",
      "We believe in",
      "data transparency",
      ". See the SQL behind every query, export results as a Jupyter notebook, and view our",
      "stats engines on GitHub",
      ".",
      "We are fanatical about",
      "performance",
      ". Our",
      "SDKs",
      "are crazy fast, lightweight, and evaluate everything locally with no network requests.",
      "We believe in",
      "open source",
      ". GrowthBook is open source and free to use. You can run it on your own infrastructure or use our hosted version.",
      "We believe in",
      "privacy & security",
      ". We don't collect any data about your users, and you can run GrowthBook on your own infrastructure.",
      "We believe good ideas come from everywhere. GrowthBook gives you feature flags, making it easy to",
      "test everything",
      "and seamlessly integrate experimentation into your process.",
      "Documentation",
      "​",
      "Use the menu or the",
      "Previous",
      "/",
      "Next",
      "links to navigate these docs.",
      "Join us on Slack",
      "if you need help, want to chat, or are thinking of a new feature. We're here to help—and to make GrowthBook even better.",
      "Edit this page",
      "Next",
      "How it works"
    ],
    "removed_content": [],
    "summary": "新增内容: Overview...",
    "url": "https://docs.growthbook.io/",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:43:47",
    "hash": "e934a4bb858f4dfb45bf6b0503b00d8e",
    "content": "关于 ABetterChoice\n​\nABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、\n实验分析\n和\nROI 仪表盘\n，以便于进行在线实验。\n入门指南\n​\n要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：\n创建项目\n：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。\nSDK 集成\n：集成 SDK 以快速开始收集洞察。\n数据连接\n：本指南介绍如何将您的数据源连接到 ABetterChoice。\n数据源与指标\n：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。\n开始您的第一个实验\n：本指南介绍如何在 ABetterChoice 中创建并运行实验。\n实验分析\n：本指南介绍如何解读 ABetterChoice 中的实验结果。\n如何使用 ROI 仪表盘\n：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/getting-started/overview",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:43:49",
    "hash": "e1b5ce3557f17232fbfe758ac92eee8e",
    "content": "Platform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPlatform\nResources\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\nPlatform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\n📢 Announcing the Statsig <> Azure AI Integration\n·\nLearn more\nfunction scrollCalendarContainer(pixels) {\n    $d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })\n  }\nProduct Updates\nNov 2024\n⏱️Experiment Compute Overview\n🏭 Autoscale on Snowflake WHN\n👁️ Single value views\n➕Cumulative Sum Rollups\n📐Retention Metrics on Statsig WHN\nOct 2024\n🎉 SCIM User Provisioning\n📋 Dynamic Configs Now Have Templates!\n⏱️WHN Compute Transparency\n⚡Inline Power Analysis\n🥇 First-Value metrics\n🔍 Focused Analysis with Top Group Limits\n🪵🪄 Log transforms\n⌚💰📊 Latest value metrics\n🧲 Group-by in Retention Analysis\n👯 Cohort analysis in all charts types\n📊 Cohort Analysis in Funnels\n🪜Funnels Now Support Up to 15 Steps\n🔗 Improved Segment Integration\n⏱️ 2x Funnel Performance Improvements\n💥 Cross-Environment Feature Gates View\n🚫 Metrics Update: Deprecating event_dau metric\nSep 2024\n🕧 Time to Complete Metrics\n⏳Funnels ++ on WHN\n📊 Distribution Analysis of Event Property Values\n% Percentage-Based Grouping\n⏰ Time Period Comparison in Funnels\n⏳ Funnels - Time to Convert Improvements\n⏸️ Pause Experiment Assignment\n🔔 Email Notification Preferences\n👤 ID Resolution++\nAug 2024\n🎛️ Dashboard Filters\n🧠 Experiment Knowledge Base\n🎓 Meta Analysis : August Release\n🧲 Retention Overhaul\n✨🛤️✨User Journeys Overhaul\n📅 Expanded Chart Granularities and MAU support\n📧 Dashboard PDF Export\n🚀❤️📊 Statsig <3 Funnels\n🕒 Session Analytics Private Beta\n📋 Custom Experiment Checklist\n📈 WHN Product Analytics\n🤖 Bot Filtering\n🤳 Parameter Stores\nJul 2024\n📊 Benjamini-Hochberg\n🔗 Combine Events in Funnel Steps\n🔍 First-Time Filters in Funnels\n🌊 Session Streams\n⌨️ Keyboard Navigation\n📊 Outlier Detection\n💾 Reusable Cohorts\n🧢 Capped Metrics (WHN)\n🕵 Differential Impact Detection\n💄 New look and feel on Statsig\n👩‍💻 Statsig Managed API Proxy\n🏠 New Home Experience\n🧮 Improved Formula Support\n🙋‍♀️ User Management v2\n🎓 Meta Analysis : July release\nJun 2024\n🌓 One Sided Tests\n♻️ WHN Statsig Table Lifecycle\n✨Dashboard Templates\n🧭 Updated navigation\n👩🏼‍💻 Statsig CLI (”Siggy”)\n📍 Advanced Local Metrics - WHN\n🔽 Pulse Lift View Selector\nℹ️ Metric Detail Cards\n💻 New Suite of Javascript SDKs\n🎓 Meta-analysis : June Release\nMay 2024\n⚡WHN SDK events now hourly\n💾 Saved Queries\n💻 Web Analytics\n🎯 Inline Targeting Criteria\n🎂 Stratified Sampling\n📃 Tables as Metric Sources\n🥷🏼 Statsig ID Resolver\n🎯 Multi-Event Cohorts\n🫀 SDK Health Visibility\n🔽 Funnels 2.0\nApr 2024\n🎯 Assignment Filtering on WHN\n📏 Threshold Metrics on WHN\n🧢 Capped Metrics\n⏯️ Statsig Session Replay Beta\n👥 Teams Configuration Settings\n🆕 Refreshing Pulse (Scorecards)\n📍Local Metrics on WHN\n📋 Schemas for Dynamic Configs\n💬 Comments in Dynamic Configs\n🧮 More Metric Flexibility on WHN\nMar 2024\n🌸 Dashboards Spring Cleaning\n📤 Templates\n🍯 Persistent Assignment\n🚨 Alerts++\n% Percentile Metrics\n🥽 visionOS support\n🔍 Diagnostics 2.0\n🧮 New Metric Types on WHN\n🤼 Teams\nFeb 2024\nSlice by Feature Gate group in Metrics Explorer\n🚫 Read Only Metric Definitions\nSlice Experiments by User Dimension in Metrics Explorer\nUser Journeys (Beta)\n👤 Anonymous -> User ID\n🕒 Scheduled Reloads\n🤖 Statbot (in Console)\n✅ Verified Metrics\nJan 2024\nEvent-Based Cohorts in Metrics Explorer\nSlice by Experiment Group in Metrics Explorer\nNew Group Assignment Health Check\nDec 2023\nNew Year, New (& Improved) Console\nNew & Improved Custom Queries\nNov 2023\nEnhanced Formulas in Metrics Explorer\n📣 Interactive Experiment Summaries\nImproved Power Analysis Calculator\nOct 2023\n📊 Improving Charts in Dashboards\nExperiment Summary PDF\nSep 2023\nNew Experiment Scorecard (Pulse) Views\n🪦Metric Archival\nAug 2023\n📝 Smart Scorecard Limits\n🚨Experiment Policy\n👩‍💻 Github Code References\nNew & Improved Experiment Setup Checklist\nBetter Experiment Defaults\nJul 2023\nAnalytics : Custom retention reports\nExperiment on the edge with Fastly\nBayesian Analysis for Experiments\n📊Bar Charts in Metrics Explorer\nStatsig Warehouse Native\nJun 2023\nCustom roles for Role Based Access Control\n📈 Metrics Explorer\nFaster Users Tab to troubleshoot in production\nMay 2023\nTargeting on Holdouts\n⌛ 90-day Pulse expiration\nCloning Metrics\nApr 2023\nFaster Pulse, Environments in Overrides, Experiment Duration by Exposures\nManual assignment for Stratified Sampling\nWarehouse ingestion tab makeover\nMar 2023\n📊 Explore metrics outside just an experiment\n🧮 Including targeting gates in your power calculations\nLeft navigation bar auto-collapse, permanent and stale gates\nMetric Alerts\nComposite Sums, Pass Rate Filter, Permanent Gates, and More\nFeb 2023\nFlexible Environment Configuration and Metrics Directionality\nDatadog Trigger Integration\nManaging Feature Gate Lifecycle, Including Cleanup\nJan 2023\nMetrics Archival, Deletion and More!\nDec 2022\nHistorical Pulse Results, Following Tags, and Custom Metrics Improvements\nData Warehouse Ingestion\nMonitoring Metrics & Explore in Feature Gates\nNov 2022\nNew Slack Integration\nOct 2022\nv1 Dashboards, Discussion Tags, and Advanced Search\nDeeper Amplitude Integration\nNew Sequential Testing Capabilities\nSep 2022\nExperiment Setup Configuration UX, Automated A/A Test Reports, and more\nBroader ID Support in Autotune and Downloadable Events Explorer Results\nHome Tab Updates\nSnowflake, Redshift, BigQuery Data Warehouse Support\nAug 2022\nExplore Tab, Search Improvements, and More\nReviews at Various Levels, Metrics Bulk Management, New Users Tab, and More\nJul 2022\nImages for Experiment Groups\nMetrics Logstream and Experiment Checklist\nExperiment Scorecard and CUPED\nJun 2022\nCustom Metrics, Filtered Search, and more\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nExperiment Compute Summary\nFollowing up from the Statsig\nproject level compute summary\n, we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to\noptimize costs\n.\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nAutoscaling on Snowflake (Warehouse Native)\nYou can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to\nSettings > Project > Data Connection,\nand select\nSet up additional Warehouses\n.\nWhen you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.\nWe have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!\n11/20/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n👁️ Updated\nSingle Value Views in Metric Drilldown and Dashboards\nUse Case\nWhen you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.\nWhy It’s Important\nSingle Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.\nThe Feature: What It Does\nYou can now directly select\nSingle Value\nas a widget type when adding items to your\nDashboards\n, making it easier to showcase key metrics prominently without additional configuration.\nIn addition, within\nMetric Drilldown\n, you can choose the Single Value view to display your metric as a headline figure. This feature offers:\nLatest Full Data Point:\nView the most recent complete data point (e.g., yesterday’s total sales or user activities).\nOverall Value for Time Range:\nSee the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.\nComparison Options:\nSelect a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.\nBy incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.\n11/5/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n➕Cumulative Sum Rollups in Metric Drilldown\nUse Case\nWhen analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:\n“How many times has this feature ever been used?\n“How many distinct people have ever used this feature?”\n“What is the total revenue generated up to this point?”\nWhy It’s Important\nViewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.\nThe Feature: What It Does\nIn\nMetric Drilldown\n, after selecting an event and choosing an aggregation method—such as\nEvent Count\n,\nUniques\n,\nAverage of Property Value\n, etc.—you can now apply the\nCumulative Sum\noption to your results. This feature accumulates your selected metric over time, providing a running total in your charts.\nWhen the metric aggregation is set to\nUniques\n, you have two options for calculating the cumulative sum:\nDistinct Uniques\nWhat it does\n: Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.\nUse Case\n: Answers\n“How many distinct people have ever used this feature?”\nby providing a deduplicated cumulative count.\nTotal Uniques\nWhat it does\n: Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.\nUse Case\n: Helps you understand\n“What is the total number of unique user engagements over time, including repeat users?”\nThis provides insight into recurring user activity across different periods.\nFor other aggregation types:\nEvent Count\n: The cumulative sum shows the total number of events over time, helping you track overall engagement.\nAverage of Property Value\n: Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.\nSum of Property Value:\nAccumulates the sum of a chosen property value from your events, useful for questions like \"\nWhat is the total revenue generated up to this point?\"\nor\n“What is the cumulative sum of this property over time?”\nby providing the total accumulated value.\nBy enabling the\nCumulative Sum\noption, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.\n11/4/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\nStatsig Cloud launched with user accounting metrics -\nincluding retention\n. We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!\nRetention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.\nThis allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.\nThis class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo\nused retention metrics\nto measure and drive long-term install and revenue growth.\nCheck out the\ndocs\n, and try it out in Warehouse Native today!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nIntroducing Open-Beta SCIM Support on Statsig\nWe're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,\nStatsig Docs\n.\nThis is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!\nKey Features\nUser Provisioning\n: Automatically create and manage user accounts in Statsig based on Okta identities\nRole Assignment\n: Easily assign and manage user roles through Okta, ensuring consistent access controls\nBenefits:\nStreamlined User Management\n: Simplify the onboarding process with automated account creation and updates.\nEnhanced Security\n: Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.\nImproved Efficiency\n: Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.\nScalability\n: Easily manage user identities as your organization grows, without the hassle of manual interventions.\nThis enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nExtending Templates to Dynamic Configs\nOver the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!\nQuick context on Dynamic Configs\nDynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.\nTemplates\nTemplates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via\nOrganization Settings\nand\nRole-based Access Controls\n) or at the\nTeam-level\n.\n10/29/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nWarehouse Native Compute Transparency Dashboard\nStatsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.\nCommon customers we've designed the dashboard to be able to address include\nWhat Metric Sources take the most compute time (useful to focus optimization effort here; see tips\nhere\n)\nWhat is the split of compute time between full loads vs incremental loads vs custom queries?\nHow is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)\nYou can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview\nThis is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.\n10/25/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nPower Analysis attached to Experiments\nPower Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.\nThis feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.\nExperiment Setup Screen\nStarting Power Analysis from an Experiment\n10/25/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\n🥇 First-Value metrics\nAlongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.\nLearn more in\nour documentation\nJoin the #1 experimentation community\nConnect with like-minded product leaders, data scientists, \n      and engineers to share the latest in product experimentation.\nJoin Community\nOlder updates\nTry Statsig Today\nGet started for free. Add your whole team!\nSign up for Free\nTest Drive Now\nWhy the best build with us\nTestimonials\nAt OpenAI, we want to iterate as fast as possible.\nStatsig enables us to grow, scale, and learn efficiently\n. Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.\nOpenAI\nDave Cummings\nEngineering Manager, ChatGPT\nMore stories\nBrex's mission is to help businesses move fast.\nStatsig is now helping our engineers move fast\n. It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.\nBrex\nKarandeep Anand\nPresident\nMore stories\nAt Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.\nStatsig's experimentation platform enables both this speed and learning for us\n.\nNotion\nMengying Li\nData Science Manager\nMore stories\nWe evaluated Optimizely, LaunchDarkly, Split, and Eppo, but\nultimately selected Statsig due to its comprehensive end-to-end integration\n. We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.\nSoundCloud\nDon Browning\nSVP, Data & Platform Engineering\nMore stories\nWe only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.\nWe are definitely heading in the right direction with Statsig\n.\nAncestry\nPartha Sarathi\nDirector of Engineering\nMore stories\nconst vocLength = 5;\n  let prevSelectedVoiceIndex = vocLength - 1;\n  function _selectVoice(index) {\n    if (index === prevSelectedVoiceIndex) {\n      return;\n    }\n    const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;\n    const voiceId = `voiceHeading${index}`;\n    $d(prevVoiceId).classList.remove('selected');\n    $d(voiceId).classList.add('selected');\n\n    const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;\n    const voiceContentId = `voiceContent${index}`;\n    $d(prevVoiceContentId).style.opacity = 0;\n    $d(prevVoiceContentId).classList.remove('onTop');\n    $d(voiceContentId).style.opacity = 1;\n    $d(voiceContentId).classList.add('onTop');\n\n    prevSelectedVoiceIndex = index;\n  }\n  _selectVoice(0);\nWe use cookies to ensure you get the best experience on our website.\nPrivacy Policy\nGot it!\nid=\"cookieConsent\"\nid=\"pageContent\"\nid=\"pageBody\"\nconst ccKey = '_cc_shown=1';\n  window.__ccKey = ccKey;\n  function setCookieConsent() {\n    let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);\n    document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;\n    document.getElementById('cookieConsent').style.display = 'none';\n  }\nBuild. Measure. Ship. Confidently!\nGet Started\nBook a Live Demo\nPlatform\nFeature Management\nExperimentation\nData Warehouse\nProduct Analytics\nSession Replay\nWeb Analytics\nAll Features\nTest Drive Now\nWhy Statsig\nProduct Observability\nHow It Works\nBuild vs Buy\nPricing\nCustomer Stories\nTestimonials\nResources\nDocs\nCode\nBlog\nProduct Updates\n<li>\n                <a href=\"/kb\" data-event-value=\"kb\">\n                  Knowledge Base\n                </a>\n              </li>\nA/B Test Calculator\nIntegrations\nStartup Program\nJoin Community\nEvents\nFeedback\nStatus\nCompany\nAbout Us\nCareers\nPets\nTerms\nPrivacy Policy\nContact Us\n© 2024 Statsig, Inc.\nHello from Bellevue, WA\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://www.statsig.com/updates",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:43:50",
    "hash": "63e816965bd712e6c9cddc9b0fb61480",
    "content": "Overview\nIntroduction\nGrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers.\nIt's great whether you're looking to just analyze experiment results or looking to make it easier to deploy code.\nGot questions?\nWe would love to help you get started with GrowthBook. You can\nmeet with us\nor\njoin our Slack\nQuick Links\n​\nHow it works\nLearn about what GrowthBook does and how it works\nQuick Start\nGet GrowthBook running in 10 minutes\nGet our open source guide to successful A/B testing and using GrowthBook\nThis guide outlines everything you need to know as you scale up experimentation at your company. It covers everything from foundational knowledge (“What is an A/B test?”) to advanced topics and common mistakes.\nOur Goals\n​\nCompanies invest thousands of hours building internal tools for feature flagging and experimentation (A/B testing). They do this to run these systems on their own infrastructure, utilize their own data, and ensure deep integration with their code.\nGrowthBook gives data, engineering, and product teams the power of a customizable platform without needing to build it themselves.\nWe believe that\nfeature flagging\nis the best way to release features, and\nA/B testing\nis the best way to measure their impact.\nWe believe A/B testing should sit on top of your\nexisting data and metrics\n, wherever they live and however they are defined.\nWe believe in\ndata transparency\n. See the SQL behind every query, export results as a Jupyter notebook, and view our\nstats engines on GitHub\n.\nWe are fanatical about\nperformance\n. Our\nSDKs\nare crazy fast, lightweight, and evaluate everything locally with no network requests.\nWe believe in\nopen source\n. GrowthBook is open source and free to use. You can run it on your own infrastructure or use our hosted version.\nWe believe in\nprivacy & security\n. We don't collect any data about your users, and you can run GrowthBook on your own infrastructure.\nWe believe good ideas come from everywhere. GrowthBook gives you feature flags, making it easy to\ntest everything\nand seamlessly integrate experimentation into your process.\nDocumentation\n​\nUse the menu or the\nPrevious\n/\nNext\nlinks to navigate these docs.\nJoin us on Slack\nif you need help, want to chat, or are thinking of a new feature. We're here to help—and to make GrowthBook even better.\nEdit this page\nNext\nHow it works\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.growthbook.io/",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:44:55",
    "hash": "e934a4bb858f4dfb45bf6b0503b00d8e",
    "content": "关于 ABetterChoice\n​\nABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、\n实验分析\n和\nROI 仪表盘\n，以便于进行在线实验。\n入门指南\n​\n要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：\n创建项目\n：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。\nSDK 集成\n：集成 SDK 以快速开始收集洞察。\n数据连接\n：本指南介绍如何将您的数据源连接到 ABetterChoice。\n数据源与指标\n：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。\n开始您的第一个实验\n：本指南介绍如何在 ABetterChoice 中创建并运行实验。\n实验分析\n：本指南介绍如何解读 ABetterChoice 中的实验结果。\n如何使用 ROI 仪表盘\n：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/getting-started/overview",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:44:57",
    "hash": "e1b5ce3557f17232fbfe758ac92eee8e",
    "content": "Platform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPlatform\nResources\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\nPlatform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\n📢 Announcing the Statsig <> Azure AI Integration\n·\nLearn more\nfunction scrollCalendarContainer(pixels) {\n    $d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })\n  }\nProduct Updates\nNov 2024\n⏱️Experiment Compute Overview\n🏭 Autoscale on Snowflake WHN\n👁️ Single value views\n➕Cumulative Sum Rollups\n📐Retention Metrics on Statsig WHN\nOct 2024\n🎉 SCIM User Provisioning\n📋 Dynamic Configs Now Have Templates!\n⏱️WHN Compute Transparency\n⚡Inline Power Analysis\n🥇 First-Value metrics\n🔍 Focused Analysis with Top Group Limits\n🪵🪄 Log transforms\n⌚💰📊 Latest value metrics\n🧲 Group-by in Retention Analysis\n👯 Cohort analysis in all charts types\n📊 Cohort Analysis in Funnels\n🪜Funnels Now Support Up to 15 Steps\n🔗 Improved Segment Integration\n⏱️ 2x Funnel Performance Improvements\n💥 Cross-Environment Feature Gates View\n🚫 Metrics Update: Deprecating event_dau metric\nSep 2024\n🕧 Time to Complete Metrics\n⏳Funnels ++ on WHN\n📊 Distribution Analysis of Event Property Values\n% Percentage-Based Grouping\n⏰ Time Period Comparison in Funnels\n⏳ Funnels - Time to Convert Improvements\n⏸️ Pause Experiment Assignment\n🔔 Email Notification Preferences\n👤 ID Resolution++\nAug 2024\n🎛️ Dashboard Filters\n🧠 Experiment Knowledge Base\n🎓 Meta Analysis : August Release\n🧲 Retention Overhaul\n✨🛤️✨User Journeys Overhaul\n📅 Expanded Chart Granularities and MAU support\n📧 Dashboard PDF Export\n🚀❤️📊 Statsig <3 Funnels\n🕒 Session Analytics Private Beta\n📋 Custom Experiment Checklist\n📈 WHN Product Analytics\n🤖 Bot Filtering\n🤳 Parameter Stores\nJul 2024\n📊 Benjamini-Hochberg\n🔗 Combine Events in Funnel Steps\n🔍 First-Time Filters in Funnels\n🌊 Session Streams\n⌨️ Keyboard Navigation\n📊 Outlier Detection\n💾 Reusable Cohorts\n🧢 Capped Metrics (WHN)\n🕵 Differential Impact Detection\n💄 New look and feel on Statsig\n👩‍💻 Statsig Managed API Proxy\n🏠 New Home Experience\n🧮 Improved Formula Support\n🙋‍♀️ User Management v2\n🎓 Meta Analysis : July release\nJun 2024\n🌓 One Sided Tests\n♻️ WHN Statsig Table Lifecycle\n✨Dashboard Templates\n🧭 Updated navigation\n👩🏼‍💻 Statsig CLI (”Siggy”)\n📍 Advanced Local Metrics - WHN\n🔽 Pulse Lift View Selector\nℹ️ Metric Detail Cards\n💻 New Suite of Javascript SDKs\n🎓 Meta-analysis : June Release\nMay 2024\n⚡WHN SDK events now hourly\n💾 Saved Queries\n💻 Web Analytics\n🎯 Inline Targeting Criteria\n🎂 Stratified Sampling\n📃 Tables as Metric Sources\n🥷🏼 Statsig ID Resolver\n🎯 Multi-Event Cohorts\n🫀 SDK Health Visibility\n🔽 Funnels 2.0\nApr 2024\n🎯 Assignment Filtering on WHN\n📏 Threshold Metrics on WHN\n🧢 Capped Metrics\n⏯️ Statsig Session Replay Beta\n👥 Teams Configuration Settings\n🆕 Refreshing Pulse (Scorecards)\n📍Local Metrics on WHN\n📋 Schemas for Dynamic Configs\n💬 Comments in Dynamic Configs\n🧮 More Metric Flexibility on WHN\nMar 2024\n🌸 Dashboards Spring Cleaning\n📤 Templates\n🍯 Persistent Assignment\n🚨 Alerts++\n% Percentile Metrics\n🥽 visionOS support\n🔍 Diagnostics 2.0\n🧮 New Metric Types on WHN\n🤼 Teams\nFeb 2024\nSlice by Feature Gate group in Metrics Explorer\n🚫 Read Only Metric Definitions\nSlice Experiments by User Dimension in Metrics Explorer\nUser Journeys (Beta)\n👤 Anonymous -> User ID\n🕒 Scheduled Reloads\n🤖 Statbot (in Console)\n✅ Verified Metrics\nJan 2024\nEvent-Based Cohorts in Metrics Explorer\nSlice by Experiment Group in Metrics Explorer\nNew Group Assignment Health Check\nDec 2023\nNew Year, New (& Improved) Console\nNew & Improved Custom Queries\nNov 2023\nEnhanced Formulas in Metrics Explorer\n📣 Interactive Experiment Summaries\nImproved Power Analysis Calculator\nOct 2023\n📊 Improving Charts in Dashboards\nExperiment Summary PDF\nSep 2023\nNew Experiment Scorecard (Pulse) Views\n🪦Metric Archival\nAug 2023\n📝 Smart Scorecard Limits\n🚨Experiment Policy\n👩‍💻 Github Code References\nNew & Improved Experiment Setup Checklist\nBetter Experiment Defaults\nJul 2023\nAnalytics : Custom retention reports\nExperiment on the edge with Fastly\nBayesian Analysis for Experiments\n📊Bar Charts in Metrics Explorer\nStatsig Warehouse Native\nJun 2023\nCustom roles for Role Based Access Control\n📈 Metrics Explorer\nFaster Users Tab to troubleshoot in production\nMay 2023\nTargeting on Holdouts\n⌛ 90-day Pulse expiration\nCloning Metrics\nApr 2023\nFaster Pulse, Environments in Overrides, Experiment Duration by Exposures\nManual assignment for Stratified Sampling\nWarehouse ingestion tab makeover\nMar 2023\n📊 Explore metrics outside just an experiment\n🧮 Including targeting gates in your power calculations\nLeft navigation bar auto-collapse, permanent and stale gates\nMetric Alerts\nComposite Sums, Pass Rate Filter, Permanent Gates, and More\nFeb 2023\nFlexible Environment Configuration and Metrics Directionality\nDatadog Trigger Integration\nManaging Feature Gate Lifecycle, Including Cleanup\nJan 2023\nMetrics Archival, Deletion and More!\nDec 2022\nHistorical Pulse Results, Following Tags, and Custom Metrics Improvements\nData Warehouse Ingestion\nMonitoring Metrics & Explore in Feature Gates\nNov 2022\nNew Slack Integration\nOct 2022\nv1 Dashboards, Discussion Tags, and Advanced Search\nDeeper Amplitude Integration\nNew Sequential Testing Capabilities\nSep 2022\nExperiment Setup Configuration UX, Automated A/A Test Reports, and more\nBroader ID Support in Autotune and Downloadable Events Explorer Results\nHome Tab Updates\nSnowflake, Redshift, BigQuery Data Warehouse Support\nAug 2022\nExplore Tab, Search Improvements, and More\nReviews at Various Levels, Metrics Bulk Management, New Users Tab, and More\nJul 2022\nImages for Experiment Groups\nMetrics Logstream and Experiment Checklist\nExperiment Scorecard and CUPED\nJun 2022\nCustom Metrics, Filtered Search, and more\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nExperiment Compute Summary\nFollowing up from the Statsig\nproject level compute summary\n, we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to\noptimize costs\n.\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nAutoscaling on Snowflake (Warehouse Native)\nYou can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to\nSettings > Project > Data Connection,\nand select\nSet up additional Warehouses\n.\nWhen you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.\nWe have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!\n11/20/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n👁️ Updated\nSingle Value Views in Metric Drilldown and Dashboards\nUse Case\nWhen you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.\nWhy It’s Important\nSingle Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.\nThe Feature: What It Does\nYou can now directly select\nSingle Value\nas a widget type when adding items to your\nDashboards\n, making it easier to showcase key metrics prominently without additional configuration.\nIn addition, within\nMetric Drilldown\n, you can choose the Single Value view to display your metric as a headline figure. This feature offers:\nLatest Full Data Point:\nView the most recent complete data point (e.g., yesterday’s total sales or user activities).\nOverall Value for Time Range:\nSee the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.\nComparison Options:\nSelect a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.\nBy incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.\n11/5/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n➕Cumulative Sum Rollups in Metric Drilldown\nUse Case\nWhen analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:\n“How many times has this feature ever been used?\n“How many distinct people have ever used this feature?”\n“What is the total revenue generated up to this point?”\nWhy It’s Important\nViewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.\nThe Feature: What It Does\nIn\nMetric Drilldown\n, after selecting an event and choosing an aggregation method—such as\nEvent Count\n,\nUniques\n,\nAverage of Property Value\n, etc.—you can now apply the\nCumulative Sum\noption to your results. This feature accumulates your selected metric over time, providing a running total in your charts.\nWhen the metric aggregation is set to\nUniques\n, you have two options for calculating the cumulative sum:\nDistinct Uniques\nWhat it does\n: Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.\nUse Case\n: Answers\n“How many distinct people have ever used this feature?”\nby providing a deduplicated cumulative count.\nTotal Uniques\nWhat it does\n: Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.\nUse Case\n: Helps you understand\n“What is the total number of unique user engagements over time, including repeat users?”\nThis provides insight into recurring user activity across different periods.\nFor other aggregation types:\nEvent Count\n: The cumulative sum shows the total number of events over time, helping you track overall engagement.\nAverage of Property Value\n: Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.\nSum of Property Value:\nAccumulates the sum of a chosen property value from your events, useful for questions like \"\nWhat is the total revenue generated up to this point?\"\nor\n“What is the cumulative sum of this property over time?”\nby providing the total accumulated value.\nBy enabling the\nCumulative Sum\noption, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.\n11/4/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\nStatsig Cloud launched with user accounting metrics -\nincluding retention\n. We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!\nRetention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.\nThis allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.\nThis class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo\nused retention metrics\nto measure and drive long-term install and revenue growth.\nCheck out the\ndocs\n, and try it out in Warehouse Native today!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nIntroducing Open-Beta SCIM Support on Statsig\nWe're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,\nStatsig Docs\n.\nThis is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!\nKey Features\nUser Provisioning\n: Automatically create and manage user accounts in Statsig based on Okta identities\nRole Assignment\n: Easily assign and manage user roles through Okta, ensuring consistent access controls\nBenefits:\nStreamlined User Management\n: Simplify the onboarding process with automated account creation and updates.\nEnhanced Security\n: Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.\nImproved Efficiency\n: Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.\nScalability\n: Easily manage user identities as your organization grows, without the hassle of manual interventions.\nThis enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nExtending Templates to Dynamic Configs\nOver the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!\nQuick context on Dynamic Configs\nDynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.\nTemplates\nTemplates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via\nOrganization Settings\nand\nRole-based Access Controls\n) or at the\nTeam-level\n.\n10/29/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nWarehouse Native Compute Transparency Dashboard\nStatsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.\nCommon customers we've designed the dashboard to be able to address include\nWhat Metric Sources take the most compute time (useful to focus optimization effort here; see tips\nhere\n)\nWhat is the split of compute time between full loads vs incremental loads vs custom queries?\nHow is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)\nYou can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview\nThis is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.\n10/25/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nPower Analysis attached to Experiments\nPower Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.\nThis feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.\nExperiment Setup Screen\nStarting Power Analysis from an Experiment\n10/25/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\n🥇 First-Value metrics\nAlongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.\nLearn more in\nour documentation\nJoin the #1 experimentation community\nConnect with like-minded product leaders, data scientists, \n      and engineers to share the latest in product experimentation.\nJoin Community\nOlder updates\nTry Statsig Today\nGet started for free. Add your whole team!\nSign up for Free\nTest Drive Now\nWhy the best build with us\nTestimonials\nAt OpenAI, we want to iterate as fast as possible.\nStatsig enables us to grow, scale, and learn efficiently\n. Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.\nOpenAI\nDave Cummings\nEngineering Manager, ChatGPT\nMore stories\nBrex's mission is to help businesses move fast.\nStatsig is now helping our engineers move fast\n. It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.\nBrex\nKarandeep Anand\nPresident\nMore stories\nAt Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.\nStatsig's experimentation platform enables both this speed and learning for us\n.\nNotion\nMengying Li\nData Science Manager\nMore stories\nWe evaluated Optimizely, LaunchDarkly, Split, and Eppo, but\nultimately selected Statsig due to its comprehensive end-to-end integration\n. We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.\nSoundCloud\nDon Browning\nSVP, Data & Platform Engineering\nMore stories\nWe only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.\nWe are definitely heading in the right direction with Statsig\n.\nAncestry\nPartha Sarathi\nDirector of Engineering\nMore stories\nconst vocLength = 5;\n  let prevSelectedVoiceIndex = vocLength - 1;\n  function _selectVoice(index) {\n    if (index === prevSelectedVoiceIndex) {\n      return;\n    }\n    const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;\n    const voiceId = `voiceHeading${index}`;\n    $d(prevVoiceId).classList.remove('selected');\n    $d(voiceId).classList.add('selected');\n\n    const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;\n    const voiceContentId = `voiceContent${index}`;\n    $d(prevVoiceContentId).style.opacity = 0;\n    $d(prevVoiceContentId).classList.remove('onTop');\n    $d(voiceContentId).style.opacity = 1;\n    $d(voiceContentId).classList.add('onTop');\n\n    prevSelectedVoiceIndex = index;\n  }\n  _selectVoice(0);\nWe use cookies to ensure you get the best experience on our website.\nPrivacy Policy\nGot it!\nid=\"cookieConsent\"\nid=\"pageContent\"\nid=\"pageBody\"\nconst ccKey = '_cc_shown=1';\n  window.__ccKey = ccKey;\n  function setCookieConsent() {\n    let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);\n    document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;\n    document.getElementById('cookieConsent').style.display = 'none';\n  }\nBuild. Measure. Ship. Confidently!\nGet Started\nBook a Live Demo\nPlatform\nFeature Management\nExperimentation\nData Warehouse\nProduct Analytics\nSession Replay\nWeb Analytics\nAll Features\nTest Drive Now\nWhy Statsig\nProduct Observability\nHow It Works\nBuild vs Buy\nPricing\nCustomer Stories\nTestimonials\nResources\nDocs\nCode\nBlog\nProduct Updates\n<li>\n                <a href=\"/kb\" data-event-value=\"kb\">\n                  Knowledge Base\n                </a>\n              </li>\nA/B Test Calculator\nIntegrations\nStartup Program\nJoin Community\nEvents\nFeedback\nStatus\nCompany\nAbout Us\nCareers\nPets\nTerms\nPrivacy Policy\nContact Us\n© 2024 Statsig, Inc.\nHello from Bellevue, WA\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://www.statsig.com/updates",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:44:58",
    "hash": "63e816965bd712e6c9cddc9b0fb61480",
    "content": "Overview\nIntroduction\nGrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers.\nIt's great whether you're looking to just analyze experiment results or looking to make it easier to deploy code.\nGot questions?\nWe would love to help you get started with GrowthBook. You can\nmeet with us\nor\njoin our Slack\nQuick Links\n​\nHow it works\nLearn about what GrowthBook does and how it works\nQuick Start\nGet GrowthBook running in 10 minutes\nGet our open source guide to successful A/B testing and using GrowthBook\nThis guide outlines everything you need to know as you scale up experimentation at your company. It covers everything from foundational knowledge (“What is an A/B test?”) to advanced topics and common mistakes.\nOur Goals\n​\nCompanies invest thousands of hours building internal tools for feature flagging and experimentation (A/B testing). They do this to run these systems on their own infrastructure, utilize their own data, and ensure deep integration with their code.\nGrowthBook gives data, engineering, and product teams the power of a customizable platform without needing to build it themselves.\nWe believe that\nfeature flagging\nis the best way to release features, and\nA/B testing\nis the best way to measure their impact.\nWe believe A/B testing should sit on top of your\nexisting data and metrics\n, wherever they live and however they are defined.\nWe believe in\ndata transparency\n. See the SQL behind every query, export results as a Jupyter notebook, and view our\nstats engines on GitHub\n.\nWe are fanatical about\nperformance\n. Our\nSDKs\nare crazy fast, lightweight, and evaluate everything locally with no network requests.\nWe believe in\nopen source\n. GrowthBook is open source and free to use. You can run it on your own infrastructure or use our hosted version.\nWe believe in\nprivacy & security\n. We don't collect any data about your users, and you can run GrowthBook on your own infrastructure.\nWe believe good ideas come from everywhere. GrowthBook gives you feature flags, making it easy to\ntest everything\nand seamlessly integrate experimentation into your process.\nDocumentation\n​\nUse the menu or the\nPrevious\n/\nNext\nlinks to navigate these docs.\nJoin us on Slack\nif you need help, want to chat, or are thinking of a new feature. We're here to help—and to make GrowthBook even better.\nEdit this page\nNext\nHow it works\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.growthbook.io/",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:44:58",
    "hash": "35f930e7d8646eec1963a1d837d8fef1",
    "content": "版本:1.2.0\n1.2.0 (最新)\n1.1.0\n1.0.2\n1.0.1\n1.0.0\n0.9.1\n0.9.0\n0.8.0\n0.7.1\n0.7.0\n0.6.1\n0.5.2\n0.5.1\n0.5.0\n0.4.0\nA/B Testing\n产品使用\nCurrent:\n产品使用手册\n产品使用手册\n|\n收藏\nvar article__collect =document.getElementById('article__collect');article__collect.onclick =function() {var htlp_url ='https://www.sensorsdata.cn/account/person.html';htlp_url =htlp_url + '?url=' + window.encodeURIComponent(window.location.href)\nhtlp_url =htlp_url + '&title=' + window.encodeURIComponent(document.title)\nhtlp_url =htlp_url + '&page_id=110298633';window.open(htlp_url)\n}\n试验管理\n新建编程试验\n新建多链接试验\n新建可视化试验\n新建时间片轮转试验\n新建多人群试验\n新建父子试验\n发布计划\n流量诊断\n切换试验分流主体\n参数管理\n跨项目试验导入\n自定义属性\n试验报告\n试验层\n空白域\n调试设备管理\n试验指标管理\n试验指标口径说明\n权限说明\n多时区\n注：本文档内容为神策产品使用和技术细节说明文档，不包含适销类条款；具体企业采购产品和技术服务内容，以商业采购合同为准。\n热门搜索\n新建编程试验\n新建多链接试验\n发布计划\n试验报告\n试验层\n",
    "has_update": true,
    "added_content": [
      "版本:1.2.0",
      "1.2.0 (最新)",
      "1.1.0",
      "1.0.2",
      "1.0.1",
      "1.0.0",
      "0.9.1",
      "0.9.0",
      "0.8.0",
      "0.7.1",
      "0.7.0",
      "0.6.1",
      "0.5.2",
      "0.5.1",
      "0.5.0",
      "0.4.0",
      "A/B Testing",
      "产品使用",
      "Current:",
      "产品使用手册",
      "产品使用手册",
      "|",
      "收藏",
      "var article__collect =document.getElementById('article__collect');article__collect.onclick =function() {var htlp_url ='https://www.sensorsdata.cn/account/person.html';htlp_url =htlp_url + '?url=' + window.encodeURIComponent(window.location.href)",
      "htlp_url =htlp_url + '&title=' + window.encodeURIComponent(document.title)",
      "htlp_url =htlp_url + '&page_id=110298633';window.open(htlp_url)",
      "}",
      "试验管理",
      "新建编程试验",
      "新建多链接试验",
      "新建可视化试验",
      "新建时间片轮转试验",
      "新建多人群试验",
      "新建父子试验",
      "发布计划",
      "流量诊断",
      "切换试验分流主体",
      "参数管理",
      "跨项目试验导入",
      "自定义属性",
      "试验报告",
      "试验层",
      "空白域",
      "调试设备管理",
      "试验指标管理",
      "试验指标口径说明",
      "权限说明",
      "多时区",
      "注：本文档内容为神策产品使用和技术细节说明文档，不包含适销类条款；具体企业采购产品和技术服务内容，以商业采购合同为准。",
      "热门搜索",
      "新建编程试验",
      "新建多链接试验",
      "发布计划",
      "试验报告",
      "试验层"
    ],
    "removed_content": [],
    "summary": "新增内容: 版本:1.2.0...",
    "url": "https://manual.sensorsdata.cn/abtesting/1.2.0/%E4%BA%A7%E5%93%81%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C-110298633.html",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:54:59",
    "hash": "e934a4bb858f4dfb45bf6b0503b00d8e",
    "content": "关于 ABetterChoice\n​\nABC，也被称为 ABetterChoice，是一家全面的 A/B 测试平台，专门为全球游戏工作室提供实验服务。我们的目标是通过对新功能进行科学评估，帮助游戏开发者创建出色的游戏。我们提供一系列强大的工具，如实时监控、\n实验分析\n和\nROI 仪表盘\n，以便于进行在线实验。\n入门指南\n​\n要开始使用 ABetterChoice，我们强烈建议您浏览我们详细的文档，了解所有关键功能、技术细节和示例代码。如果您对平台有任何疑问，我们的团队随时准备提供帮助，确保您能充分利用其潜力。以下指南将帮助您开始使用 ABetterChoice：\n创建项目\n：本指南介绍了使用 ABetterChoice 的第一步，即创建项目。\nSDK 集成\n：集成 SDK 以快速开始收集洞察。\n数据连接\n：本指南介绍如何将您的数据源连接到 ABetterChoice。\n数据源与指标\n：本指南介绍如何在 ABetterChoice 中配置数据源和指标，这是启动实验和解释结果的关键步骤。\n开始您的第一个实验\n：本指南介绍如何在 ABetterChoice 中创建并运行实验。\n实验分析\n：本指南介绍如何解读 ABetterChoice 中的实验结果。\n如何使用 ROI 仪表盘\n：本指南介绍如何在 ABetterChoice 平台中使用 ROI 仪表盘。\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.abetterchoice.ai/zh/guide/getting-started/overview",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:55:02",
    "hash": "e1b5ce3557f17232fbfe758ac92eee8e",
    "content": "Platform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPlatform\nResources\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\nPlatform\nResources\nDocs\nBlog\nPricing\nSign In\nBook a Live Demo\nPRODUCTS\nExperimentation\nFeature Flags\nWarehouse Native\nProduct Analytics\nSession Replay\nWeb Analytics\nROLES\nEngineering\nDev Ops\nData Science\nProduct Management\nINDUSTRIES\nArtificial Intelligence\nGaming\nB2B Saas\nE-Commerce\nCustomer Stories\nStartups\nIntegrations\nA/B Testing Calculator\nSupport\nProduct Updates\n📢 Announcing the Statsig <> Azure AI Integration\n·\nLearn more\nfunction scrollCalendarContainer(pixels) {\n    $d('calendarScoller').scrollBy({ left: pixels, behavior: 'smooth' })\n  }\nProduct Updates\nNov 2024\n⏱️Experiment Compute Overview\n🏭 Autoscale on Snowflake WHN\n👁️ Single value views\n➕Cumulative Sum Rollups\n📐Retention Metrics on Statsig WHN\nOct 2024\n🎉 SCIM User Provisioning\n📋 Dynamic Configs Now Have Templates!\n⏱️WHN Compute Transparency\n⚡Inline Power Analysis\n🥇 First-Value metrics\n🔍 Focused Analysis with Top Group Limits\n🪵🪄 Log transforms\n⌚💰📊 Latest value metrics\n🧲 Group-by in Retention Analysis\n👯 Cohort analysis in all charts types\n📊 Cohort Analysis in Funnels\n🪜Funnels Now Support Up to 15 Steps\n🔗 Improved Segment Integration\n⏱️ 2x Funnel Performance Improvements\n💥 Cross-Environment Feature Gates View\n🚫 Metrics Update: Deprecating event_dau metric\nSep 2024\n🕧 Time to Complete Metrics\n⏳Funnels ++ on WHN\n📊 Distribution Analysis of Event Property Values\n% Percentage-Based Grouping\n⏰ Time Period Comparison in Funnels\n⏳ Funnels - Time to Convert Improvements\n⏸️ Pause Experiment Assignment\n🔔 Email Notification Preferences\n👤 ID Resolution++\nAug 2024\n🎛️ Dashboard Filters\n🧠 Experiment Knowledge Base\n🎓 Meta Analysis : August Release\n🧲 Retention Overhaul\n✨🛤️✨User Journeys Overhaul\n📅 Expanded Chart Granularities and MAU support\n📧 Dashboard PDF Export\n🚀❤️📊 Statsig <3 Funnels\n🕒 Session Analytics Private Beta\n📋 Custom Experiment Checklist\n📈 WHN Product Analytics\n🤖 Bot Filtering\n🤳 Parameter Stores\nJul 2024\n📊 Benjamini-Hochberg\n🔗 Combine Events in Funnel Steps\n🔍 First-Time Filters in Funnels\n🌊 Session Streams\n⌨️ Keyboard Navigation\n📊 Outlier Detection\n💾 Reusable Cohorts\n🧢 Capped Metrics (WHN)\n🕵 Differential Impact Detection\n💄 New look and feel on Statsig\n👩‍💻 Statsig Managed API Proxy\n🏠 New Home Experience\n🧮 Improved Formula Support\n🙋‍♀️ User Management v2\n🎓 Meta Analysis : July release\nJun 2024\n🌓 One Sided Tests\n♻️ WHN Statsig Table Lifecycle\n✨Dashboard Templates\n🧭 Updated navigation\n👩🏼‍💻 Statsig CLI (”Siggy”)\n📍 Advanced Local Metrics - WHN\n🔽 Pulse Lift View Selector\nℹ️ Metric Detail Cards\n💻 New Suite of Javascript SDKs\n🎓 Meta-analysis : June Release\nMay 2024\n⚡WHN SDK events now hourly\n💾 Saved Queries\n💻 Web Analytics\n🎯 Inline Targeting Criteria\n🎂 Stratified Sampling\n📃 Tables as Metric Sources\n🥷🏼 Statsig ID Resolver\n🎯 Multi-Event Cohorts\n🫀 SDK Health Visibility\n🔽 Funnels 2.0\nApr 2024\n🎯 Assignment Filtering on WHN\n📏 Threshold Metrics on WHN\n🧢 Capped Metrics\n⏯️ Statsig Session Replay Beta\n👥 Teams Configuration Settings\n🆕 Refreshing Pulse (Scorecards)\n📍Local Metrics on WHN\n📋 Schemas for Dynamic Configs\n💬 Comments in Dynamic Configs\n🧮 More Metric Flexibility on WHN\nMar 2024\n🌸 Dashboards Spring Cleaning\n📤 Templates\n🍯 Persistent Assignment\n🚨 Alerts++\n% Percentile Metrics\n🥽 visionOS support\n🔍 Diagnostics 2.0\n🧮 New Metric Types on WHN\n🤼 Teams\nFeb 2024\nSlice by Feature Gate group in Metrics Explorer\n🚫 Read Only Metric Definitions\nSlice Experiments by User Dimension in Metrics Explorer\nUser Journeys (Beta)\n👤 Anonymous -> User ID\n🕒 Scheduled Reloads\n🤖 Statbot (in Console)\n✅ Verified Metrics\nJan 2024\nEvent-Based Cohorts in Metrics Explorer\nSlice by Experiment Group in Metrics Explorer\nNew Group Assignment Health Check\nDec 2023\nNew Year, New (& Improved) Console\nNew & Improved Custom Queries\nNov 2023\nEnhanced Formulas in Metrics Explorer\n📣 Interactive Experiment Summaries\nImproved Power Analysis Calculator\nOct 2023\n📊 Improving Charts in Dashboards\nExperiment Summary PDF\nSep 2023\nNew Experiment Scorecard (Pulse) Views\n🪦Metric Archival\nAug 2023\n📝 Smart Scorecard Limits\n🚨Experiment Policy\n👩‍💻 Github Code References\nNew & Improved Experiment Setup Checklist\nBetter Experiment Defaults\nJul 2023\nAnalytics : Custom retention reports\nExperiment on the edge with Fastly\nBayesian Analysis for Experiments\n📊Bar Charts in Metrics Explorer\nStatsig Warehouse Native\nJun 2023\nCustom roles for Role Based Access Control\n📈 Metrics Explorer\nFaster Users Tab to troubleshoot in production\nMay 2023\nTargeting on Holdouts\n⌛ 90-day Pulse expiration\nCloning Metrics\nApr 2023\nFaster Pulse, Environments in Overrides, Experiment Duration by Exposures\nManual assignment for Stratified Sampling\nWarehouse ingestion tab makeover\nMar 2023\n📊 Explore metrics outside just an experiment\n🧮 Including targeting gates in your power calculations\nLeft navigation bar auto-collapse, permanent and stale gates\nMetric Alerts\nComposite Sums, Pass Rate Filter, Permanent Gates, and More\nFeb 2023\nFlexible Environment Configuration and Metrics Directionality\nDatadog Trigger Integration\nManaging Feature Gate Lifecycle, Including Cleanup\nJan 2023\nMetrics Archival, Deletion and More!\nDec 2022\nHistorical Pulse Results, Following Tags, and Custom Metrics Improvements\nData Warehouse Ingestion\nMonitoring Metrics & Explore in Feature Gates\nNov 2022\nNew Slack Integration\nOct 2022\nv1 Dashboards, Discussion Tags, and Advanced Search\nDeeper Amplitude Integration\nNew Sequential Testing Capabilities\nSep 2022\nExperiment Setup Configuration UX, Automated A/A Test Reports, and more\nBroader ID Support in Autotune and Downloadable Events Explorer Results\nHome Tab Updates\nSnowflake, Redshift, BigQuery Data Warehouse Support\nAug 2022\nExplore Tab, Search Improvements, and More\nReviews at Various Levels, Metrics Bulk Management, New Users Tab, and More\nJul 2022\nImages for Experiment Groups\nMetrics Logstream and Experiment Checklist\nExperiment Scorecard and CUPED\nJun 2022\nCustom Metrics, Filtered Search, and more\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nExperiment Compute Summary\nFollowing up from the Statsig\nproject level compute summary\n, we've also added an experiment level compute summary - available in Experiment Diagnostics.  Out of box it lets you look at compute utilization by job type or metric source. This is helpful to isolate situations where a low value metric is a disproportionate share of compute utilization. When you find this, look at our guide to\noptimize costs\n.\n11/26/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nAutoscaling on Snowflake (Warehouse Native)\nYou can now connect multiple Snowflake warehouses to your account, enabling better query performance by automatically distributing query jobs across all available warehouses. To set it up, you can head over to\nSettings > Project > Data Connection,\nand select\nSet up additional Warehouses\n.\nWhen you schedule multiple experiments to be loaded at the same time, Statsig will distribute these queries across the provided warehouses to reduce contention. Spreading queries across compute clusters can often be faster and cheaper(!) when contention causes queries to be backed up.\nWe have a beta of intelligent Autoscaling in works. Reach out in Slack if you'd like to try it!\n11/20/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n👁️ Updated\nSingle Value Views in Metric Drilldown and Dashboards\nUse Case\nWhen you need a quick, at-a-glance summary of a key metric, having a single, prominent value can provide immediate insight. Whether you’re monitoring yesterday’s user sign-ups or the total revenue over the past month, a headline figure helps you stay informed without diving into detailed charts.\nWhy It’s Important\nSingle Value views allow you to focus on the most critical data points instantly. This feature is especially useful on dashboards, where quick visibility into key metrics supports faster decision-making and keeps your team aligned on important performance indicators.\nThe Feature: What It Does\nYou can now directly select\nSingle Value\nas a widget type when adding items to your\nDashboards\n, making it easier to showcase key metrics prominently without additional configuration.\nIn addition, within\nMetric Drilldown\n, you can choose the Single Value view to display your metric as a headline figure. This feature offers:\nLatest Full Data Point:\nView the most recent complete data point (e.g., yesterday’s total sales or user activities).\nOverall Value for Time Range:\nSee the cumulative or average value over the entire selected time range, providing a broader perspective on your metric.\nComparison Options:\nSelect a comparison period to see absolute and percentage changes over time, helping you understand trends and growth.\nBy incorporating Single Value views into your dashboards and analyses, you can highlight essential metrics at a glance, enabling you and your team to stay updated with minimal effort.\n11/5/2024\nPermalink ›\nAkin Olugbade\nProduct Manager, Statsig\n➕Cumulative Sum Rollups in Metric Drilldown\nUse Case\nWhen analyzing event data, you often need to understand the cumulative impact of your metrics over time. For example:\n“How many times has this feature ever been used?\n“How many distinct people have ever used this feature?”\n“What is the total revenue generated up to this point?”\nWhy It’s Important\nViewing metrics as a cumulative sum provides valuable insights into long-term trends and overall growth. It helps you track feature adoption, user engagement, and total impact over time, enabling more informed decision-making.\nThe Feature: What It Does\nIn\nMetric Drilldown\n, after selecting an event and choosing an aggregation method—such as\nEvent Count\n,\nUniques\n,\nAverage of Property Value\n, etc.—you can now apply the\nCumulative Sum\noption to your results. This feature accumulates your selected metric over time, providing a running total in your charts.\nWhen the metric aggregation is set to\nUniques\n, you have two options for calculating the cumulative sum:\nDistinct Uniques\nWhat it does\n: Counts each unique user or unit only once in the cumulative total, regardless of how many times they appear in subsequent time periods.\nUse Case\n: Answers\n“How many distinct people have ever used this feature?”\nby providing a deduplicated cumulative count.\nTotal Uniques\nWhat it does\n: Counts each occurrence of a user or unit every time they appear, allowing them to be counted multiple times in the cumulative total.\nUse Case\n: Helps you understand\n“What is the total number of unique user engagements over time, including repeat users?”\nThis provides insight into recurring user activity across different periods.\nFor other aggregation types:\nEvent Count\n: The cumulative sum shows the total number of events over time, helping you track overall engagement.\nAverage of Property Value\n: Accumulates average values over time, useful for metrics like cumulative revenue or total session duration.\nSum of Property Value:\nAccumulates the sum of a chosen property value from your events, useful for questions like \"\nWhat is the total revenue generated up to this point?\"\nor\n“What is the cumulative sum of this property over time?”\nby providing the total accumulated value.\nBy enabling the\nCumulative Sum\noption, you can transform your metric analyses to capture total impact over time, providing a comprehensive view that supports deeper insights into your product’s performance.\n11/4/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\nStatsig Cloud launched with user accounting metrics -\nincluding retention\n. We’re now matching this capability with highly flexible Retention Metrics in Warehouse Native. For insight into why we think this matters, check out our blog post!\nRetention metrics allow you to calculate the rolling daily retention from one event/user-day status to itself - or another, if desired. The time window retention is measured in is fully customizable - for example, you can measure the % of users that retain into the last 3 days of the next week, exactly 14 days from now, or any time in the next two weeks.\nThis allows you to directly track if features designed to make your product more interesting, enjoyable, or stickier over time are working, instead of trying to divine this from some combination of “DAU” and “users active at 7/14/28 days from exposure”.\nThis class of metrics is critical for growth teams focused on growing their userbase; Lenny’s Newsletter published a fantastic piece on how Duolingo\nused retention metrics\nto measure and drive long-term install and revenue growth.\nCheck out the\ndocs\n, and try it out in Warehouse Native today!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nIntroducing Open-Beta SCIM Support on Statsig\nWe're excited to announce the beta launch of SCIM (System for Cross-domain Identity Management) support on Statsig! This initial release focuses on seamless integration with Okta for efficient user provisioning and role assignment into your Statsig projects. For more information visit,\nStatsig Docs\n.\nThis is an Enterprise-only feature. If you would like to enroll in the open beta and enable SCIM for your organization, please reach out to us!\nKey Features\nUser Provisioning\n: Automatically create and manage user accounts in Statsig based on Okta identities\nRole Assignment\n: Easily assign and manage user roles through Okta, ensuring consistent access controls\nBenefits:\nStreamlined User Management\n: Simplify the onboarding process with automated account creation and updates.\nEnhanced Security\n: Centralized identity governance reduces the risk of unauthorized access by ensuring accurate role assignments.\nImproved Efficiency\n: Save time and reduce errors with automated workflows, allowing your team to focus on higher-priority tasks.\nScalability\n: Easily manage user identities as your organization grows, without the hassle of manual interventions.\nThis enhancement streamlines user management and improves security by centralizing identity governance. Stay tuned for more updates as we expand SCIM support in the future!\n10/31/2024\nPermalink ›\nShubham Singhal\nProduct Manager, Statsig\nExtending Templates to Dynamic Configs\nOver the last couple of months, we have seen an influx in the usage of our Dynamic Configs product. We heard from our customers that they would like to create templates for Dynamic Configs that can be re-used by your team or organization. Templates have always existed on Statsig for Feature Gates and Experiments, and now we have extended this feature to Dynamic Configs as well!\nQuick context on Dynamic Configs\nDynamic Configs is a tool used to change application settings in real-time without requiring a restart or redeployment of the application. This allows developers to control operational settings like performance tuning or scaling resources or other configurations on the fly.\nTemplates\nTemplates enable you to create a blueprint for Dynamic Configs to enable standardization and reusability across your project. Templates can help enforce a standard practice, or make it easy for new configs to get up & running. Templates can be enforced at the Org (via\nOrganization Settings\nand\nRole-based Access Controls\n) or at the\nTeam-level\n.\n10/29/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nWarehouse Native Compute Transparency Dashboard\nStatsig Warehouse Native now lets you get a birds eye view across the compute time experiment analysis incurs in your warehouse. Break this down by experiment, metric source or type of query to find what to optimize.\nCommon customers we've designed the dashboard to be able to address include\nWhat Metric Sources take the most compute time (useful to focus optimization effort here; see tips\nhere\n)\nWhat is the split of compute time between full loads vs incremental loads vs custom queries?\nHow is compute time distributed across experiments? (useful to make sure value realized and compute costs incurred are roughly aligned)\nYou can find this dashboard in the Left Nav under Analytics -> Dashboards -> Pipeline Overview\nThis is built using Statsig Product Analytics - you can customize any of these charts, or build new ones yourself. A favorite is to add in your average compute cost, so you can turn slot time per experiment into $ cost per experiment.\n10/25/2024\nPermalink ›\nVineeth Madhusudanan\nProduct Manager, Statsig\nPower Analysis attached to Experiments\nPower Analysis is critical input into experiment durations when you care about trustworthy experiments. When you perform Power Analysis for an experiment, the analysis is now automatically attached to the experiment and available to other reviewers. When you start Power Analysis for an experiment, we'll prepopulate any Primary Metrics you've already configured on the experiment.\nThis feature is rolling out to Statsig Cloud and Warehouse Native customers over the next week.\nExperiment Setup Screen\nStarting Power Analysis from an Experiment\n10/25/2024\nPermalink ›\nCraig Sexauer\nData Scientist, Statsig\n🥇 First-Value metrics\nAlongside latest value metrics, we’re also announcing First-Value metrics. These allow you to see the value from the first record the user logged while exposed to an experiment. Imagine being able to track first purchase value, first subscription plan price, or first-time time-to-load on a new page.\nLearn more in\nour documentation\nJoin the #1 experimentation community\nConnect with like-minded product leaders, data scientists, \n      and engineers to share the latest in product experimentation.\nJoin Community\nOlder updates\nTry Statsig Today\nGet started for free. Add your whole team!\nSign up for Free\nTest Drive Now\nWhy the best build with us\nTestimonials\nAt OpenAI, we want to iterate as fast as possible.\nStatsig enables us to grow, scale, and learn efficiently\n. Integrating experimentation with product analytics and feature flagging has been crucial for quickly understanding and addressing our users' top priorities.\nOpenAI\nDave Cummings\nEngineering Manager, ChatGPT\nMore stories\nBrex's mission is to help businesses move fast.\nStatsig is now helping our engineers move fast\n. It has been a game changer to automate the manual lift typical to running experiments and has helped product teams ship the right features to their users quickly.\nBrex\nKarandeep Anand\nPresident\nMore stories\nAt Notion, we're continuously learning what our users value and want every team to run experiments to learn more. It’s also critical to maintain speed as a habit.\nStatsig's experimentation platform enables both this speed and learning for us\n.\nNotion\nMengying Li\nData Science Manager\nMore stories\nWe evaluated Optimizely, LaunchDarkly, Split, and Eppo, but\nultimately selected Statsig due to its comprehensive end-to-end integration\n. We wanted a complete solution rather than a partial one, including everything from the stats engine to data ingestion.\nSoundCloud\nDon Browning\nSVP, Data & Platform Engineering\nMore stories\nWe only had so many analysts. Statsig provided the necessary tools to remove the bottleneck. I know that we are able to impact our key business metrics in a positive way with Statsig.\nWe are definitely heading in the right direction with Statsig\n.\nAncestry\nPartha Sarathi\nDirector of Engineering\nMore stories\nconst vocLength = 5;\n  let prevSelectedVoiceIndex = vocLength - 1;\n  function _selectVoice(index) {\n    if (index === prevSelectedVoiceIndex) {\n      return;\n    }\n    const prevVoiceId = `voiceHeading${prevSelectedVoiceIndex}`;\n    const voiceId = `voiceHeading${index}`;\n    $d(prevVoiceId).classList.remove('selected');\n    $d(voiceId).classList.add('selected');\n\n    const prevVoiceContentId = `voiceContent${prevSelectedVoiceIndex}`;\n    const voiceContentId = `voiceContent${index}`;\n    $d(prevVoiceContentId).style.opacity = 0;\n    $d(prevVoiceContentId).classList.remove('onTop');\n    $d(voiceContentId).style.opacity = 1;\n    $d(voiceContentId).classList.add('onTop');\n\n    prevSelectedVoiceIndex = index;\n  }\n  _selectVoice(0);\nWe use cookies to ensure you get the best experience on our website.\nPrivacy Policy\nGot it!\nid=\"cookieConsent\"\nid=\"pageContent\"\nid=\"pageBody\"\nconst ccKey = '_cc_shown=1';\n  window.__ccKey = ccKey;\n  function setCookieConsent() {\n    let exp = new Date(Date.now() + 365 * 24 * 3600 * 1000);\n    document.cookie = `${ccKey}; expires=${exp.toUTCString()}; path=/`;\n    document.getElementById('cookieConsent').style.display = 'none';\n  }\nBuild. Measure. Ship. Confidently!\nGet Started\nBook a Live Demo\nPlatform\nFeature Management\nExperimentation\nData Warehouse\nProduct Analytics\nSession Replay\nWeb Analytics\nAll Features\nTest Drive Now\nWhy Statsig\nProduct Observability\nHow It Works\nBuild vs Buy\nPricing\nCustomer Stories\nTestimonials\nResources\nDocs\nCode\nBlog\nProduct Updates\n<li>\n                <a href=\"/kb\" data-event-value=\"kb\">\n                  Knowledge Base\n                </a>\n              </li>\nA/B Test Calculator\nIntegrations\nStartup Program\nJoin Community\nEvents\nFeedback\nStatus\nCompany\nAbout Us\nCareers\nPets\nTerms\nPrivacy Policy\nContact Us\n© 2024 Statsig, Inc.\nHello from Bellevue, WA\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://www.statsig.com/updates",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:55:02",
    "hash": "63e816965bd712e6c9cddc9b0fb61480",
    "content": "Overview\nIntroduction\nGrowthBook is an open-source platform for feature flagging and A/B testing built for data teams, engineers, and product managers.\nIt's great whether you're looking to just analyze experiment results or looking to make it easier to deploy code.\nGot questions?\nWe would love to help you get started with GrowthBook. You can\nmeet with us\nor\njoin our Slack\nQuick Links\n​\nHow it works\nLearn about what GrowthBook does and how it works\nQuick Start\nGet GrowthBook running in 10 minutes\nGet our open source guide to successful A/B testing and using GrowthBook\nThis guide outlines everything you need to know as you scale up experimentation at your company. It covers everything from foundational knowledge (“What is an A/B test?”) to advanced topics and common mistakes.\nOur Goals\n​\nCompanies invest thousands of hours building internal tools for feature flagging and experimentation (A/B testing). They do this to run these systems on their own infrastructure, utilize their own data, and ensure deep integration with their code.\nGrowthBook gives data, engineering, and product teams the power of a customizable platform without needing to build it themselves.\nWe believe that\nfeature flagging\nis the best way to release features, and\nA/B testing\nis the best way to measure their impact.\nWe believe A/B testing should sit on top of your\nexisting data and metrics\n, wherever they live and however they are defined.\nWe believe in\ndata transparency\n. See the SQL behind every query, export results as a Jupyter notebook, and view our\nstats engines on GitHub\n.\nWe are fanatical about\nperformance\n. Our\nSDKs\nare crazy fast, lightweight, and evaluate everything locally with no network requests.\nWe believe in\nopen source\n. GrowthBook is open source and free to use. You can run it on your own infrastructure or use our hosted version.\nWe believe in\nprivacy & security\n. We don't collect any data about your users, and you can run GrowthBook on your own infrastructure.\nWe believe good ideas come from everywhere. GrowthBook gives you feature flags, making it easy to\ntest everything\nand seamlessly integrate experimentation into your process.\nDocumentation\n​\nUse the menu or the\nPrevious\n/\nNext\nlinks to navigate these docs.\nJoin us on Slack\nif you need help, want to chat, or are thinking of a new feature. We're here to help—and to make GrowthBook even better.\nEdit this page\nNext\nHow it works\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://docs.growthbook.io/",
    "error": false
  },
  {
    "timestamp": "2024-11-27 19:55:03",
    "hash": "35f930e7d8646eec1963a1d837d8fef1",
    "content": "版本:1.2.0\n1.2.0 (最新)\n1.1.0\n1.0.2\n1.0.1\n1.0.0\n0.9.1\n0.9.0\n0.8.0\n0.7.1\n0.7.0\n0.6.1\n0.5.2\n0.5.1\n0.5.0\n0.4.0\nA/B Testing\n产品使用\nCurrent:\n产品使用手册\n产品使用手册\n|\n收藏\nvar article__collect =document.getElementById('article__collect');article__collect.onclick =function() {var htlp_url ='https://www.sensorsdata.cn/account/person.html';htlp_url =htlp_url + '?url=' + window.encodeURIComponent(window.location.href)\nhtlp_url =htlp_url + '&title=' + window.encodeURIComponent(document.title)\nhtlp_url =htlp_url + '&page_id=110298633';window.open(htlp_url)\n}\n试验管理\n新建编程试验\n新建多链接试验\n新建可视化试验\n新建时间片轮转试验\n新建多人群试验\n新建父子试验\n发布计划\n流量诊断\n切换试验分流主体\n参数管理\n跨项目试验导入\n自定义属性\n试验报告\n试验层\n空白域\n调试设备管理\n试验指标管理\n试验指标口径说明\n权限说明\n多时区\n注：本文档内容为神策产品使用和技术细节说明文档，不包含适销类条款；具体企业采购产品和技术服务内容，以商业采购合同为准。\n热门搜索\n新建编程试验\n新建多链接试验\n发布计划\n试验报告\n试验层\n",
    "has_update": false,
    "added_content": [],
    "removed_content": [],
    "summary": "无更新",
    "url": "https://manual.sensorsdata.cn/abtesting/1.2.0/%E4%BA%A7%E5%93%81%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C-110298633.html",
    "error": false
  }
]